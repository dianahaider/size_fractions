{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "cd872fb8",
   "metadata": {},
   "source": [
    "## Upload functions and necessary modules"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f12e05f1",
   "metadata": {},
   "outputs": [],
   "source": [
    "from bb2022_functions import *\n",
    "%matplotlib inline\n",
    "from Bio.SeqIO.FastaIO import SimpleFastaParser\n",
    "from Bio import SeqIO\n",
    "pd.options.mode.chained_assignment = None  # default='warn'"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ef8c5429",
   "metadata": {},
   "source": [
    "## Import and format metadata"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fb6bbc2a",
   "metadata": {},
   "outputs": [],
   "source": [
    "md = pd.read_csv(\"/Users/Diana/Documents/escuela/phd/size_fractions_copy/metadata_merged.csv\")\n",
    "merged = pd.read_csv(\"/Users/Diana/Documents/escuela/phd/size_fractions_copy/metadata_niskin.csv\")\n",
    "all_md = pd.read_csv(\"/Users/Diana/Documents/escuela/phd/size_fractions_copy/allmetadata.csv\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "402ff79a",
   "metadata": {},
   "source": [
    "### Visualize metadata"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "da41acb5",
   "metadata": {},
   "outputs": [],
   "source": [
    "maxvals = plot_nutrients(all_md, 60)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "dbc70d5e",
   "metadata": {},
   "source": [
    "## Add microbial communities"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "479815e8",
   "metadata": {},
   "outputs": [],
   "source": [
    "#generate a dataframe from all specified amplicon\n",
    "df, comm = consolidate_tables('16S')#, frac='pooled') #16S, chloroplast, or 18S\n",
    "merged = merge_metadata(df, all_md)\n",
    "separated, contaminants = pick_metadata(comm, merged)\n",
    "newseparated = make_defract(all_md, separated)\n",
    "#apply changes to taxonomy according to NCBI identified ASVs\n",
    "newdf = apply_replacement(newseparated, \"feature_id\", \"Genus\") \n",
    "#newdf = apply_replacement(newdf, \"feature_id\", \"PRSpecies\") \n",
    "# or replace Genus with PRSpecies if dealing with phytoref"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "bec056f9",
   "metadata": {},
   "source": [
    "### Use these lines for analysis of P"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a546059c",
   "metadata": {},
   "outputs": [],
   "source": [
    "#this is all the weeks and depths which we selected for comparison with P\n",
    "weeks_depths_with_P = newdf[newdf['size_code'] == 'P'][['weekn', 'depth']].drop_duplicates()\n",
    "filtered_df = newdf.merge(weeks_depths_with_P, on=['weekn', 'depth']) #filter the original df to only keep those samples\n",
    "newdf = filtered_df"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "83ddee89",
   "metadata": {
    "collapsed": true
   },
   "source": [
    "#### Inspect the dna concentrations, and read depth of samples"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "82cec6f5",
   "metadata": {},
   "outputs": [],
   "source": [
    "#plot of dna concentrations per sample\n",
    "dnacon(newdf, depth='all', includeSL=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3738433b",
   "metadata": {},
   "outputs": [],
   "source": [
    "#rarefaction curves per community\n",
    "rarefy_curve(comm, newdf)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3d5a8df5",
   "metadata": {},
   "source": [
    "We can also sort the samples by their library size:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "75273c16",
   "metadata": {},
   "outputs": [],
   "source": [
    "newseparated[['Total','sampleid']].sort_values('Total').drop_duplicates()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0808dc1c",
   "metadata": {},
   "outputs": [],
   "source": [
    "#separately copy newseparated from each comm into 'proks', 'euks', and 'chloro'\n",
    "combined = pd.concat([proks, euks, chloro], ignore_index=True)\n",
    "agg_counts = combined.groupby(['weekn','comm'])['feature_frequency'] \\\n",
    "                     .sum().unstack('comm')\n",
    "\n",
    "fig, ax = plt.subplots(figsize=(12,4))\n",
    "agg_counts.plot(ax=ax)\n",
    "ax.set_yscale('log')\n",
    "ax.set_xlabel('Week number')\n",
    "ax.set_ylabel('Feature frequency (log scale)')\n",
    "ax.set_title('Raw counts per community (all depths summed)')\n",
    "ax.legend(title='Community', bbox_to_anchor=(1.02,1), loc='upper left')\n",
    "plt.tight_layout()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2dac37ce",
   "metadata": {},
   "outputs": [],
   "source": [
    "#this code was corrected by AI\n",
    "sample_counts = newseparated.groupby('sampleid')['feature_frequency'].sum()\n",
    "#calculate % kept read for various sampling depths to pick one\n",
    "percentiles = [10, 25, 50, 75]\n",
    "depths = [int(np.percentile(sample_counts, p)) for p in percentiles]\n",
    "depths += [int(sample_counts.min()), int(sample_counts.max())]\n",
    "depths = sorted(set(depths))\n",
    "\n",
    "retained = [(sample_counts >= d).sum() for d in depths]\n",
    "percent_retained = [r / len(sample_counts) * 100 for r in retained]\n",
    "table = pd.DataFrame({\n",
    "    'Depth': depths,\n",
    "    'Samples Retained': retained,\n",
    "    'Percent Retained (%)': np.round(percent_retained, 1)\n",
    "})\n",
    "table"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "65f1a0c0",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Added repeat-rarefaction step for alpha diversity comparisons\n",
    "rarefaction_depths = [5000, 10000]  # example depths\n",
    "\n",
    "df_merged = newseparated.copy()\n",
    "feature_table = newseparated.pivot_table(\n",
    "    index='sampleid', columns='feature_id', values='feature_frequency', fill_value=0\n",
    ")\n",
    "\n",
    "for depth in rarefaction_depths:\n",
    "    summary_stats = repeat_rarefy(feature_table, depth=depth, n_iter=100)\n",
    "    summary_stats_flat = summary_stats.copy()\n",
    "    summary_stats_flat.columns = ['_'.join(col) + f\"_{depth}\" for col in summary_stats_flat.columns]\n",
    "    summary_stats_flat = summary_stats_flat.reset_index()\n",
    "    # Merge with the cumulative df\n",
    "    df_merged = df_merged.merge(summary_stats_flat, on='sampleid', how='left')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b928aa15",
   "metadata": {},
   "outputs": [],
   "source": [
    "sizecodes = ['S', 'L', 'W', 'SL']\n",
    "palette_colors = sns.color_palette()\n",
    "palette_dict = {sizecode: color for sizecode, color in zip(sizecodes, palette_colors)}\n",
    "\n",
    "#print y=Total to check library depth, and y=nASVs\n",
    "d1_rarefied = df_merged[df_merged[\"depth\"] == 5]\n",
    "sns.lineplot(data=d1_rarefied.sort_values('weekn'), x='weekn', y='richness_mean_5000', marker='o', hue='size_code',\n",
    "            palette=palette_dict)\n",
    "plt.tight_layout()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ebab5e55",
   "metadata": {},
   "source": [
    "#### Explore the taxonomy in the samples and compare"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "945f9da7",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Produce interactive taxonomic barplots with plotly\n",
    "phyld, top10d = taxbarplot(comm, newdf, 'Genus', depth=60, topn=10, colrow='size_code')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5be826b3",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Visualize the static barplots with seaborn, and each size fraction separately\n",
    "taxonomic_barplots(comm, newdf, [5,60], 'Genus', 21, False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8d3b4e56",
   "metadata": {},
   "outputs": [],
   "source": [
    "taxonomic_barplots_p(comm, newdf, [5,60], 'Genus', 21, True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c534508d",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Generate the heatmap for the top genus from each sample\n",
    "heatmap_top1(comm, newdf, 'Genus')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a79860e0",
   "metadata": {},
   "outputs": [],
   "source": [
    "#use this to inspect taxonomy of specific feature ids 'f_id'\n",
    "f_id = '25679bd7ae54946d9d7348b7fde04db4'\n",
    "newdf.loc[newdf['feature_id'] == f_id, 'Taxon'].tolist()[0]"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "baae7dca",
   "metadata": {},
   "source": [
    "The above plot uses taxonomy, but we can generate the same plot but by comparing whether 80% of the features in each samples are also found in the whole (unfractionated samples). This was quantified by dividing the number of shared features by the toal number of features. If a square has a red color (closer to 1), it's very similar to the unfractionated sample, and the bluer the square, the more different it is from the unfractionated."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8afbafc9",
   "metadata": {},
   "outputs": [],
   "source": [
    "grab_80perc(comm, newseparated, 0.8, 'feature_id')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5f2a2e05",
   "metadata": {},
   "source": [
    "We can plot alpha diversity measurements, whether as 'shannon_diversity' or 'nASVs' which is the richness quantified by the total number of ASVs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "155a887c",
   "metadata": {},
   "outputs": [],
   "source": [
    "#run the visualisations for alpha diversity and run pairwise t-tests between size fractions for richness values\n",
    "anova, results = boxplot_depth(newdf, comm, 60, 'nASVs', 'Shannon Diversity Index')\n",
    "#results gives the corrected p-values for pairwise comparisons"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5c2f3943",
   "metadata": {},
   "outputs": [],
   "source": [
    "results"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "14ac93b5",
   "metadata": {},
   "source": [
    "Compare the slopes of linear regressions of the richness change over time. Each value represents how much a size fraction (column) differs in comparison to the average slope (averaged between all size fractions) for each depth (rows)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d4d80b53",
   "metadata": {},
   "outputs": [],
   "source": [
    "tohm, z_sc_df = get_slopes(comm, separated)\n",
    "#a zscore of 1= 1 std away from the mean,\n",
    "#positive values=higher than mean, neg= smaller than mean"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "917d1bc5",
   "metadata": {},
   "source": [
    "### Venn diagrams for features unique to size fractions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d33b73c8",
   "metadata": {},
   "outputs": [],
   "source": [
    "dfplot, level, dfplot_unweighted = calcperc_defrac_unweighted(comm, newdf, 'feature_id')\n",
    "dfplot, level, dfplot_unweighted = calcperc_defrac(comm, newdf, 'feature_id', dfplot_unweighted)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a3d26b36",
   "metadata": {},
   "outputs": [],
   "source": [
    "f_id = '000527117f05c819fdf7268c540a4a3b'\n",
    "newdf.loc[newdf['feature_id'] == f_id, 'Taxon'].tolist()[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "13b16fd1",
   "metadata": {},
   "outputs": [],
   "source": [
    "timeseries_fid(comm, newseparated, f_id, 's__uncultured_Alphaproteobacteria', 30)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "efa8fadd",
   "metadata": {},
   "source": [
    "### Beta diversity and ANCOM analysis"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d19b1a82",
   "metadata": {},
   "source": [
    "Optionally we can run ANCOM with removed low abundance features with a given threshold"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "bc00b39d",
   "metadata": {},
   "outputs": [],
   "source": [
    "#only if we want to run ANCOM pairwise\n",
    "news2 = newseparated[newseparated.size_code != 'L']\n",
    "news2 = news2[news2.size_code != 'SL']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b563f2f4",
   "metadata": {},
   "outputs": [],
   "source": [
    "depths = [1,5,10,30,60]\n",
    "for depth in depths:\n",
    "    pca, pca_features, sfdclr, dm = pcaplot(newdf, depth, comm, 'size_code', 'DFr', 'week')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "70cabc53",
   "metadata": {},
   "outputs": [],
   "source": [
    "depths = [1,5,10,30,60]\n",
    "for depth in depths:\n",
    "    pca, pca_features, sfdclr, dm = pcaplot(newdf, depth, comm, 'size_code', 'DFr', 'week')\n",
    "    DAresults, DARejected_SC_taxonomy, prcentile = run_ancom(comm, newdf, sfdclr, depth, 'size_code', threshold=0)\n",
    "\n",
    "    #save outputs\n",
    "    DAresults.to_csv('outputs/ANCOM/chloroplast/none/'+comm+'_D'+str(depth)+'_WSLSL.csv')\n",
    "    DARejected_SC_taxonomy.to_csv('outputs/ANCOM/chloroplast/none/'+comm+'_D'+str(depth)+'_Trueonly_WSLSL.csv')\n",
    "\n",
    "    notify()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ad2da992",
   "metadata": {},
   "source": [
    "Bray-curtis analysis of SL against W pre-bloom and bloom"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c019199b",
   "metadata": {},
   "outputs": [],
   "source": [
    "ft = newseparated.pivot_table(\n",
    "    index=['weekn', 'depth', 'size_code'],\n",
    "    columns='feature_id',\n",
    "    values='feature_frequency',\n",
    "    fill_value=0\n",
    ")\n",
    "\n",
    "### check if clr transform from sci py\n",
    "def clr_transform(arr):\n",
    "    return clr(arr + 0.1)\n",
    "\n",
    "\n",
    "rows = []\n",
    "for (week, depth), group in ft.groupby(level=[0, 1]):\n",
    "    # try to extract SL and W for this (week, depth)\n",
    "    try:\n",
    "        sl = group.xs('SL', level=2).values.flatten()\n",
    "        w  = group.xs('W',  level=2).values.flatten()\n",
    "    except KeyError:\n",
    "        continue  # skip if SL or W is missing\n",
    "\n",
    "    # clr transformation\n",
    "    sl_clr = clr_transform(sl)\n",
    "    w_clr  = clr_transform(w)\n",
    "\n",
    "    # compute Bray–Curtis\n",
    "    bc = braycurtis(sl_clr, w_clr)\n",
    "\n",
    "    # determine bloom stage here\n",
    "    stage = 'Pre-bloom' if week < 8 else 'Bloom'\n",
    "\n",
    "    rows.append({\n",
    "        'weekn': week,\n",
    "        'depth': depth,\n",
    "        'braycurtis': bc,\n",
    "        'stage': stage\n",
    "    })\n",
    "\n",
    "bc_df = pd.DataFrame(rows)\n",
    "\n",
    "print(\"Columns in bc_df:\", bc_df.columns.tolist())\n",
    "\n",
    "sns.catplot(\n",
    "    data=bc_df,\n",
    "    x='stage',\n",
    "    y='braycurtis',\n",
    "    hue='depth',\n",
    "    kind='point',\n",
    "    dodge=True,\n",
    "    capsize=0.1,\n",
    "    height=5,\n",
    "    aspect=1 \n",
    ")\n",
    "plt.ylabel('Bray-Curtis distance (SL and W)')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d412eea7",
   "metadata": {},
   "source": [
    "Depending on ancom results, we can investigate single features temporal dynamics"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cd391fcc",
   "metadata": {},
   "outputs": [],
   "source": [
    "f_id = 'f3aa3ab8b0d2a94859675d59169af75'\n",
    "newdf.loc[newdf['feature_id'] == f_id, 'Taxon'].tolist()[0]"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9c0abfc9",
   "metadata": {},
   "source": [
    "Visualize the time series of a single feature in each size fraction over the 16 weeks"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0e5bfdc0",
   "metadata": {},
   "outputs": [],
   "source": [
    "timeseries_fid(comm, newseparated, f_id, 'g__Caenarcaniphilales', 1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "56cc9acd",
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "feature_id_summary = count_feature_id_presence_with_depth_and_W('outputs', comm)\n",
    "top_asvs_summary = filter_top_asvs(feature_id_summary, method=\"top_W_sum\", n=50)\n",
    "plot_asv_heatmap(comm, feature_id_summary, file_filter=\"WSLSL\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "cb8900a1",
   "metadata": {},
   "source": [
    "### Export files"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4312145a",
   "metadata": {},
   "source": [
    "#### Files for NCBI"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "631b6453",
   "metadata": {},
   "source": [
    "To generate MIMARKS file for NCBI sequence submission; the output is a .csv file for the samples and their metadata for submission (i.e sampleid, size fraction, date)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5782332e",
   "metadata": {},
   "outputs": [],
   "source": [
    "make_MIMARKS(newseparated)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9f02d3d5",
   "metadata": {},
   "source": [
    "#### Files for R"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f8bdf7ac",
   "metadata": {},
   "source": [
    "To create a phyloseq object, you need an ASV table, taxonomy file and metadata"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8fde9651",
   "metadata": {},
   "outputs": [],
   "source": [
    "correlation_df = correlation_df.sort_values(by='correlation', ascending=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4903a4d8",
   "metadata": {},
   "outputs": [],
   "source": [
    "correlation_df.sort_values('correlationé')"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "qiime2-2023.5",
   "language": "python",
   "name": "qiime2-2023.5"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.16"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
