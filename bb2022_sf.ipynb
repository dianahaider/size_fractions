{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Upload functions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from bb2022_functions import *\n",
    "%matplotlib inline\n",
    "from Bio.SeqIO.FastaIO import SimpleFastaParser\n",
    "from Bio import SeqIO\n",
    "pd.options.mode.chained_assignment = None  # default='warn'"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Import and format metadata from lab, and BBMP"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "md = pd.read_csv(\"metadata_merged.csv\")\n",
    "merged = pd.read_csv(\"metadata_niskin.csv\")\n",
    "all_md = pd.read_csv(\"allmetadata.csv\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "detect_anomalies('Temperature_y', all_md, 1, yr={2022}, month={1,2,3,4,5})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "d1 = all_md.loc[all_md['depth'] == 1]\n",
    "d1 = d1[['weekn', 'depth', 'Phosphate',\n",
    "       'Ammonia', 'Chlorophyll A']]\n",
    "d1.rename(columns={'Temperature_x': 'Temperature'},\n",
    "          inplace= True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "d1 = d1.melt(id_vars=['weekn', 'depth'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_stage(weekNb):\n",
    "    if weekNb <8:\n",
    "        return 'Pre-bloom'\n",
    "    elif weekNb >= 8:\n",
    "        return 'Bloom'\n",
    "\n",
    "d1['Time'] = d1['weekn'].apply(get_stage)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df1 = d1[d1['Time'] == 'Bloom']\n",
    "df2 = d1[d1['Time'] == 'Pre-bloom']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "sns.lmplot(\n",
    "    data = d1,\n",
    "    x=\"weekn\", y=\"value\",\n",
    "    hue = 'variable', palette = 'viridis', scatter=True\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "sns.lmplot(x='weekn', y='value', data=df1, hue='variable') \n",
    "sns.lmplot(x='weekn', y='value', data=df2, hue='variable')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "d1 = all_md.loc[all_md['depth'] == 1]\n",
    "d1 = d1[['weekn', 'Temperature_x']]\n",
    "d1.rename(columns={'Temperature_x': 'Temperature'},\n",
    "          inplace= True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "d1.drop_duplicates(inplace=True)\n",
    "d1.set_index('weekn', inplace=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "rolling_mean = d1.rolling(5).mean()\n",
    "rolling_std = d1.rolling(5).std()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.plot(d1, color=\"blue\",label=\"Temperature\")\n",
    "plt.plot(rolling_mean, color=\"red\", label=\"Rolling Mean Temperature\")\n",
    "plt.plot(rolling_std, color=\"black\", label = \"Rolling Standard Deviation Temperate\")\n",
    "plt.title(\"Passenger Time Series, Rolling Mean, Standard Deviation\")\n",
    "#plt.legend(loc=\"upper right\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "autocorrelation_lag1 = d1['Temperature'].autocorr(lag=1)\n",
    "print(\"One Month Lag: \", autocorrelation_lag1)\n",
    "\n",
    "autocorrelation_lag3 = d1['Temperature'].autocorr(lag=3)\n",
    "print(\"Three Month Lag: \", autocorrelation_lag3)\n",
    "\n",
    "autocorrelation_lag6 = d1['Temperature'].autocorr(lag=6)\n",
    "print(\"Six Month Lag: \", autocorrelation_lag6)\n",
    "\n",
    "autocorrelation_lag9 = d1['Temperature'].autocorr(lag=9)\n",
    "print(\"Nine Month Lag: \", autocorrelation_lag9)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from statsmodels.tsa.seasonal import seasonal_decompose"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "decompose = seasonal_decompose(d1['Temperature'],model='multiplicative', period=3)\n",
    "trend = decompose.trend\n",
    "residual = decompose.resid\n",
    "\n",
    "decompose.plot();\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "sns.relplot(\n",
    "    data=d1, x=\"weekn\", y=\"value\",\n",
    "    row=\"depth\", hue=\"variable\",\n",
    "    kind=\"line\"\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Add microbial community"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Data prep"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#generate a dataframe from all specified amplicon\n",
    "df, comm = consolidate_tables('18S')\n",
    "merged = merge_metadata(df, all_md)\n",
    "separated = pick_metadata(merged)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Remove chloroplast, cyanobacteria"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "searchfor = [\"Cyanobacteria\", \"Chloroplast\"]\n",
    "contaminants = separated[separated.Taxon.str.contains('|'.join(searchfor))]\n",
    "separated = separated[~separated.Taxon.str.contains('|'.join(searchfor))]\n",
    "separated = separated.reset_index(drop=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#run these lines to switch to chloroplast comm\n",
    "separated = contaminants.copy()\n",
    "separated = separated.reset_index(drop=True)\n",
    "comm = 'chloroplast'\n",
    "\n",
    "#add phytorep taxonomy\n",
    "cp_tax = pd.read_csv('chloroplast/taxonomy.tsv', sep='\\t')\n",
    "cp_tax = cp_tax.rename(columns={\"Feature ID\": \"feature_id\", \"Taxon\": \"PRTaxon\", \"Confidence\":\"PRConfidence\"})\n",
    "separated = pd.merge(separated, cp_tax, on=\"feature_id\", how=\"left\")\n",
    "separated['PRSpecies'] = separated['PRTaxon'].str.split('|').str[-1]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#re-calculate ratios when removing chloroplast for 16S\n",
    "separated['Total'] = separated['feature_frequency'].groupby(separated['sampleid']).transform('sum')\n",
    "separated['ratio'] = separated['feature_frequency']/separated['Total']\n",
    "separated['nASVs'] = separated['feature_id'].groupby(separated['sampleid']).transform('count')\n",
    "separated['weekdepth'] = separated[\"weekn\"].astype(str) + separated[\"depth\"].astype(str)\n",
    "separated['avg'] = separated['nASVs'].groupby(separated['weekdepth']).transform('mean')\n",
    "separated['diff'] = separated['nASVs'] - separated['avg']"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Run the following code to generate \"newseparated\" which is the union of small and large size fractions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "newseparated = make_defract(all_md, separated)\n",
    "newseparated[\"rank\"] = newseparated.groupby(\"sampleid\")[\"ratio\"].rank(method=\"average\", ascending=False)\n",
    "newseparated[\"ranktot\"] = newseparated['rank'] / newseparated['nASVs']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "calcop = newseparated[['nASVs', 'feature_frequency', 'size_code', 'feature_id']]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "calcop.groupby('size_code')['feature_frequency'].sum()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "comm"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "calcop['feature_id'].nunique()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "tohm, z_sc_df = get_slopes(comm, separated)\n",
    "#a zscore of 1= 1 std away from the mean,\n",
    "#positive values=higher than mean, neg= smaller than mean"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "sns.lineplot(data=newseparated, x=\"depth\", y=\"nASVs\", hue='size_code')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "grab_80perc(comm, newseparated, 0.8, 'feature_id')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df = newseparated\n",
    "perc = 0.8\n",
    "level = 'feature_id'\n",
    "\n",
    "df.sort_values(by=['sampleid','ratio'], ascending=[True,False], inplace=True)\n",
    "df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df['cumul'] = df.groupby('sampleid')['ratio'].transform(pd.Series.cumsum)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_Grouped = df.groupby(['sampleid']).agg({'cumul': [('Count', 'count'),\n",
    "                                                               ('Topn80', lambda x: len(x[x<0.8]))]}).reset_index()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#find the nearest larger neighbor to 80% (to include the asv that is within the 80%)\n",
    "df['difperc']=(df['cumul']-perc)\n",
    "df1=df[df['difperc'] > 0].groupby('sampleid').min().reset_index().reindex()\n",
    "df1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "    #remove the ASVs not in the 80%\n",
    "    df1 = df1[['sampleid', 'cumul']]\n",
    "    df1.rename(columns={\"cumul\": \"maxval\"}, errors=\"raise\", inplace=True)\n",
    "    df = df.merge(df1,on='sampleid')\n",
    "    df = df[df['cumul']<df['maxval']] #filter out the ASVs that are less than the 80% of reads\n",
    "\n",
    "    #subselect only columns of interest\n",
    "    df= df[['sampleid', level, 'feature_frequency', 'weekn', 'size_code', 'depth']]\n",
    "\n",
    "    #get the list of top ASVs from the whole fraction\n",
    "    dfW = df[df.size_code == 'W']\n",
    "    df3 = dfW.groupby(['weekn', 'depth'])[level].apply(list).reset_index(name='tocompareagainst')\n",
    "    df3['weekdpth'] = df3[\"weekn\"].astype(str) + df3[\"depth\"].astype(str)\n",
    "\n",
    "    #get the list of top ASVs from all the size fractions\n",
    "    dfSLSL = df[df.size_code != 'W']\n",
    "    df4 = dfSLSL.groupby(['weekn', 'depth','size_code'])[level].apply(list).reset_index(name='tocomparewith')\n",
    "    df4['tocomparewith'] = df4['tocomparewith'].apply(lambda x: list(set(x)))\n",
    "\n",
    "    #merge with the list from Whole\n",
    "    df5 = df4.merge(df3, on=['weekn', 'depth'], how='outer')\n",
    "\n",
    "    #make a list of the top 80% reads ASVs ids\n",
    "    df5['tocompareagainst'] = df5['tocompareagainst'].apply(lambda d: d if isinstance(d, list) else [])\n",
    "    df5['tocompareagainst'] = df5['tocompareagainst'].apply(lambda x: list(set(x)))\n",
    "\n",
    "    #make a list of the intersection, i.e. ASVs in top80% of reads shared between any size fraction and W\n",
    "    df5['intersection'] = [list(set(a).intersection(set(b)))\n",
    "                          for a, b in zip(df5.tocomparewith, df5.tocompareagainst)]\n",
    "\n",
    "    #make a list of the differences\n",
    "    df5['difference'] = df5['tocomparewith'].map(set) - df5['tocompareagainst'].map(set)\n",
    "\n",
    "    #calculate the size of the intersection as a percetnage\n",
    "    df5['lengthinter'] = df5['intersection'].str.len()\n",
    "    df5['lengthtotal'] = df5['tocompareagainst'].str.len()\n",
    "    df5['lengthperc'] = df5['lengthinter']/df5['lengthtotal']\n",
    "    df5[[\"depth\"]] = df5[[\"depth\"]].apply(pd.to_numeric)\n",
    "    df5.sort_values(['depth', 'size_code'], inplace=True)\n",
    "    df5['weekdpth'] = df5[\"depth\"].astype(str) + df5['size_code'].astype(str)\n",
    "\n",
    "    #save the output as csv to inspect groups\n",
    "    df5.to_csv('outputs/'+comm+'/intersection_with_W'+level+'_'+str(perc)+'.csv')\n",
    "\n",
    "    ordered_yaxis = df5['weekdpth'].tolist()\n",
    "\n",
    "    mylist = uniqlist(ordered_yaxis)\n",
    "\n",
    "\n",
    "    glue = df5.pivot(index=\"weekdpth\", columns=\"weekn\", values=\"lengthperc\")\n",
    "    glue = glue.reindex(mylist)\n",
    "    glue = glue[glue.columns].astype(float)\n",
    "    if incl_mean == True:\n",
    "        glue['mean'] = glue.mean(axis=1)\n",
    "        glue.to_csv('outputs/'+comm+'/interesction_with_W_'+level+'_'+str(perc)+'.csv')\n",
    "\n",
    "    sns.set_style('ticks')\n",
    "    plt.figure(figsize=(5, 4.4))\n",
    "\n",
    "\n",
    "    ax = sns.heatmap(glue, fmt='f', yticklabels=True, linewidths=.5, cmap=sns.color_palette(\"coolwarm\", as_cmap=True))\n",
    "    ax.axhline(3, ls='--')\n",
    "    ax.axhline(6, ls='--')\n",
    "    ax.axhline(9, ls='--')\n",
    "    ax.axhline(12, ls='--')\n",
    "\n",
    "    ax.set_xticks(range(0, 16, 5))\n",
    "\n",
    "    plt.savefig('outputs/'+comm+'/interesction_with_W_'+level+'_'+str(perc)+'.png', bbox_inches='tight', dpi=300)\n",
    "\n",
    "    plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "depth_num = {\n",
    "    \"A\": 1,\n",
    "    \"B\": 5,\n",
    "    \"C\": 10,\n",
    "    \"D\": 60,\n",
    "    \"E\": 30\n",
    "}\n",
    "\n",
    "df_Grouped.columns = df_Grouped.columns.droplevel()\n",
    "df_Grouped['Topn80'] = df_Grouped['Topn80']+1\n",
    "\n",
    "df_Grouped.rename(columns={'' :'sampleid'}, inplace=True)\n",
    "df_Grouped[\"size_code\"] = df_Grouped[\"sampleid\"].str.extract(r'[1-9][0-9]?[A-E](SL|[L-S])')\n",
    "df_Grouped[\"size_code\"] = df_Grouped[\"size_code\"].fillna('W')\n",
    "df_Grouped[\"depth_code\"] = df_Grouped[\"sampleid\"].str.extract(r'[1-9][0-9]?([A-E])')\n",
    "df_Grouped['depth']= df_Grouped['depth_code'].map(depth_num)\n",
    "df_Grouped[\"weekn\"] = df_Grouped[\"sampleid\"].str.extract(r'\\.([1-9][0-9]?)[A-E]')\n",
    "df_Grouped['weekn'] = pd.to_numeric(df_Grouped['weekn'])\n",
    "df_Grouped['depth'] = pd.to_numeric(df_Grouped['depth'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "for depth in depths:\n",
    "    df_1 = df5[df5.depth == depth]\n",
    "    sns.barplot(df_1, x=\"weekn\", y=\"lengthtotal\", hue=\"size_code\")\n",
    "    plt.savefig('outputs/'+comm+'/nASVintop'+str(depth)+'_RL_'+SFX+SFY+'.png', dpi=200, bbox_inches=\"tight\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "sns.barplot(df_1, x=\"weekn\", y=\"Topn80\", hue=\"size_code\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "separated = separated[separated.size_code != 'S']\n",
    "#separated = separated[separated.size_code != 'S']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#to import for weighted unifrac\n",
    "to_biom = onlyDFRW[['sampleid', 'feature_id', 'feature_frequency']].copy().drop_duplicates()\n",
    "to_biom = to_biom.pivot(index='sampleid', columns='feature_id', values='feature_frequency').fillna(0)\n",
    "to_biom.to_csv('newbiom'+comm+'.tsv', sep='\\t')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "table=onlyDFRW"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#loglog plot\n",
    "depths = [1,5,10,30,60]\n",
    "table = newseparated\n",
    "\n",
    "for depth in depths:\n",
    "    pca, pca_features, sfdclr, distance_matrix = pcaplot(table, depth, comm, 'size_code', 'DFr', 'week')\n",
    "    distance_matrix2 = distance_matrix.reset_index()\n",
    "    idedup = distance_matrix2['samples'].to_list()\n",
    "    dm = DistanceMatrix(distance_matrix, ids=idedup)\n",
    "    df123 = dm.to_data_frame()\n",
    "    df123.to_csv('outputs/'+comm+'/distance_matrix_d'+str(depth)+'.tsv', sep='\\t')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "upsetprep(comm, 'feature_id', separated)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "pca, pca_features, sfdclr, distance_matrix = pcaplot(newseparated, 1, comm, 'size_code', 'DFr', 'week')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "pca_features"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "import numpy as np\n",
    "\n",
    "from matplotlib.patches import Ellipse\n",
    "import matplotlib.transforms as transforms\n",
    "\n",
    "def get_correlated_dataset(n, dependency, mu, scale):\n",
    "    latent = np.random.randn(n, 2)\n",
    "    dependent = latent.dot(dependency)\n",
    "    scaled = dependent * scale\n",
    "    scaled_with_offset = scaled + mu\n",
    "    # return x and y of the new, correlated dataset\n",
    "    return scaled_with_offset[:, 0], scaled_with_offset[:, 1]\n",
    "\n",
    "fig, ax_nstd = plt.subplots(figsize=(6, 6))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "dependency_nstd = [[0.8, 0.75],\n",
    "                   [-0.2, 0.35]]\n",
    "mu = 0, 0\n",
    "scale = 8, 5"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "ax_nstd.axvline(c='grey', lw=1)\n",
    "ax_nstd.axhline(c='grey', lw=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "x, y = get_correlated_dataset(500, dependency_nstd, mu, scale)\n",
    "ax_nstd.scatter(x, y, s=0.5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "confidence_ellipse(x, y, ax_nstd, n_std=1,\n",
    "                   label=r'$1\\sigma$', edgecolor='firebrick')\n",
    "confidence_ellipse(x, y, ax_nstd, n_std=2,\n",
    "                   label=r'$2\\sigma$', edgecolor='fuchsia', linestyle='--')\n",
    "confidence_ellipse(x, y, ax_nstd, n_std=3,\n",
    "                   label=r'$3\\sigma$', edgecolor='blue', linestyle=':')\n",
    "\n",
    "ax_nstd.scatter(mu[0], mu[1], c='red', s=3)\n",
    "ax_nstd.set_title('Different standard deviations')\n",
    "ax_nstd.legend()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "confidence_ellipse(x, y, ax_nstd, n_std=1,\n",
    "                   label=r'$1\\sigma$', edgecolor='firebrick')\n",
    "confidence_ellipse(x, y, ax_nstd, n_std=2,\n",
    "                   label=r'$2\\sigma$', edgecolor='fuchsia', linestyle='--')\n",
    "confidence_ellipse(x, y, ax_nstd, n_std=3,\n",
    "                   label=r'$3\\sigma$', edgecolor='blue', linestyle=':')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "ax_nstd.scatter(mu[0], mu[1], c='red', s=3)\n",
    "ax_nstd.set_title('Different standard deviations')\n",
    "ax_nstd.legend()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "newseparated.drop_duplicates(inplace=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "depth=1\n",
    "level = 'Genus'\n",
    "table = newseparated\n",
    "sfd=table[table.depth==depth]\n",
    "toptaxa = sfd[['feature_frequency', 'ratio', 'Taxon', 'size_code', 'depth','weekn', level]].copy()\n",
    "toptaxa = toptaxa.drop_duplicates()\n",
    "df_agg = toptaxa.groupby(['size_code',level, 'weekn']).agg({'ratio':sum})\n",
    "topd = df_agg['ratio'].groupby(['size_code', 'weekn'], group_keys=False).nlargest(4)\n",
    "topd = topd.to_frame()\n",
    "topd = topd.reset_index()\n",
    "\n",
    "taxonomy = table[[level, 'Taxon']].copy()\n",
    "taxonomy.drop_duplicates(inplace=True)\n",
    "\n",
    "tosave = pd.merge(topd, taxonomy, how ='inner', on=level)\n",
    "tosave.sort_values(['weekn', 'size_code']).to_csv(str(depth)+comm+'top3.csv')\n",
    "\n",
    "tosave=tosave.sort_values(['weekn', 'size_code'])\n",
    "\n",
    "tosave['weekfid'] = tosave[\"weekn\"].astype(str) + tosave[\"size_code\"].astype(str)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "fig = px.bar(tosave, x=\"size_code\", y=\"ratio\", facet_col=\"weekn\", color=level, labels={\n",
    "                     \"ratio\": \"Relative abundance\",\n",
    "                     \"size_code\": \"\",\n",
    "                     \"weekn\": \"w\"}, hover_data=[\"Taxon\"], width=950, height=1000)\n",
    "\n",
    "fig.update_xaxes(type='category', dtick=1)\n",
    "fig.update_layout(\n",
    "    #title= text=\"Relative abundance of top\"+str(topn) + level + 'observed at Depth' + str(depth),\n",
    "    yaxis_title=\"Relative abundance\",\n",
    "    xaxis_title=\"Size fraction\",\n",
    "    legend_title=level,\n",
    "    font=dict(size=8),\n",
    "    legend=dict(\n",
    "        orientation=\"h\",\n",
    "        yanchor=\"bottom\",\n",
    "        y=-1,\n",
    "        xanchor=\"right\",\n",
    "        x=1\n",
    "    )\n",
    ")\n",
    "\n",
    "fig.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "topiv = tosave[['feature_id', 'ratio', 'weekfid']].copy()\n",
    "topiv = topiv.drop_duplicates()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "original_order = topiv[\"weekfid\"].unique()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "sfdpiv= topiv.pivot(index='weekfid', columns='feature_id', values='ratio').reindex(index=original_order)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "sfdpiv=sfdpiv.fillna(0)\n",
    "sfdclr=sfdpiv.mask(sfdpiv==0).fillna(0.1)\n",
    "clr_transformed_array = clr(sfdclr)\n",
    "samples = sfdpiv.index\n",
    "asvs = sfdpiv.columns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Creating the dataframe with the clr transformed data, and assigning the sample names\n",
    "clr_transformed = pd.DataFrame(clr_transformed_array, columns=asvs)\n",
    "#Assigning the asv names\n",
    "clr_transformed['samples'] = samples\n",
    "clr_transformed = clr_transformed.set_index('samples')\n",
    "clr_transformed.head()\n",
    "\n",
    "#calculate distance matrix\n",
    "dist = cdist(clr_transformed, clr_transformed, 'euclid')\n",
    "distance_matrix = pd.DataFrame(dist, columns=samples)\n",
    "distance_matrix['samples'] = samples\n",
    "distance_matrix = distance_matrix.set_index('samples')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "fig = px.imshow(distance_matrix)\n",
    "fig.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "comm"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "pca, pca_features, sfdclr, distance_matrix = pcaplot(newseparated, 'all', comm, 'size_code', 'DFr', 'week')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#df=newseparated[newseparated.depth==1]\n",
    "df=newseparated.copy()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "topiv = df[['feature_id', 'feature_frequency', 'sampleid']].copy()\n",
    "topiv = topiv.drop_duplicates()\n",
    "\n",
    "sfdpiv= topiv.pivot(index='sampleid', columns='feature_id', values='feature_frequency')\n",
    "sfdpiv=sfdpiv.fillna(0)\n",
    "sfdclr=sfdpiv.mask(sfdpiv==0).fillna(0.1)\n",
    "clr_transformed_array = clr(sfdclr)\n",
    "samples = sfdpiv.index\n",
    "asvs = sfdpiv.columns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plot_df = pd.DataFrame(data = pca_features, columns = ['dim1', 'dim2'], index = sfdpiv.index)\n",
    "plot_df['dim1'] = plot_df['dim1']/1000\n",
    "plot_df['dim2'] = plot_df['dim2']/1000\n",
    "plot_df2 = pd.merge(plot_df,df[['sampleid','size_code','depth', 'weekn']],on='sampleid', how='left')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_stage(weekNb):\n",
    "    if weekNb < 8:\n",
    "        return 'Pre-bloom'\n",
    "    elif weekNb >= 8:\n",
    "        return 'Bloom'\n",
    "\n",
    "if depth != 'all':\n",
    "    plot_df2['Time'] = plot_df2['weekn'].apply(get_stage)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plot_df2.to_csv('R_results/R_testing_vis/for_R.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import plotly.express as px\n",
    "\n",
    "fig = px.scatter(plot_df2, x=\"dim1\", y=\"dim2\", color='size_code', symbol=\"depth\",\n",
    "                hover_data=['weekn', 'depth'])\n",
    "fig.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Write out fasta file of chloroplast/cyano sequences"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "fa = SeqIO.parse('chloroplast/dna-sequences.fasta' ,\n",
    "                 \"fasta\")\n",
    "seqs_i_want = [] #we'll put the good sequences here\n",
    "fid_chloro = newseparated['feature_id'].unique()\n",
    "for record in fa: #a SeqRecord has the accession as record.id, usually.\n",
    "    if record.id in fid_chloro: #This is how you check if the accession is in the values of the dict\n",
    "        seqs_i_want.append(record)\n",
    "#Now we can write the list of records to a fasta file. This will take care of the formatting etc\n",
    "with open('chloroplast/selected_dna.fasta', \"w\") as f:\n",
    "    SeqIO.write(seqs_i_want, f, \"fasta\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Richness analysis"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "sfd1 = newseparated[['sampleid','size_code', 'weekn', 'nASVs', 'depth']].copy()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#group the dataframe with all features to obtain either the mean or std of number of features per size fraction\n",
    "sfd1.groupby(['size_code']).mean()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "comm"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "sfd1.describe()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#run the visualisations for alpha diversity and run pairwise t-tests between size fractions for richness values\n",
    "anova, results = boxplot_depth(separated, comm, 5, 'nASVs', 'Number of ASVs')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "results"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "roll_avg(comm, newseparated, 1, 'nASVs',4)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df= newseparated[['sampleid', 'weekn','depth', 'size_code', 'nASVs']].copy()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df.drop_duplicates(inplace=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Simple regression analysis between pairs of size fractions"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "How to detect outliers?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "newseparated.loc[(newseparated['ratio'] > 0.25)].sort_values('ratio')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "q75, q25 = np.percentile(slwplot['L'], [75 ,25])\n",
    "iqr = q75 - q25"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "newslw = outlier(slwplot)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "newslw['L'].isna().sum()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "comm"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Run RL"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_results = SRA_pairs(comm, 'W', 'SL', newseparated, outliers='None', view=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_results"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "investigate temporal pattern thorugh all depths of outliers"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "supsel = newseparated.loc[newseparated['feature_id'] == '75ceeaa937c64399438614ca3706cf2a'].sort_values('feature_frequency')\n",
    "supsel['depth'].unique()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "sns.scatterplot(data = supsel, x = 'weekn', y = 'ratio', hue='depth')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#draw interactive plotly to identify outliers\n",
    "depth=1\n",
    "X='W'\n",
    "Y='L'\n",
    "\n",
    "d1 = newseparated.loc[newseparated['depth'] == depth]\n",
    "forpl = d1[['ratio', 'feature_id', 'sampleid', 'weekn', 'depth', 'size_code', 'Phylum', 'Family']].copy()\n",
    "slwplot = forpl.pivot_table(index=[\"feature_id\", \"depth\", 'weekn','Phylum', 'Family'], columns=\"size_code\", values='ratio').fillna(0)\n",
    "slwplot = slwplot.reset_index()\n",
    "fig = px.scatter(slwplot, x=X, y=Y, color=\"weekn\", trendline=\"ols\")\n",
    "fig.show()\n",
    "\n",
    "results = px.get_trendline_results(fig)\n",
    "print(results)\n",
    "\n",
    "#results.query(\"weekn ==  and Phylum == \").px_fit_results.iloc[0].summary()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Plot all r^2 values"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "r2vals = pd.read_csv(\"R_results/RL_results_ALL.csv\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "sns.set_theme(rc={'figure.figsize':(5,4)})\n",
    "sns.set_style(\"ticks\")\n",
    "sns.boxplot(data=r2vals, x=\"Y\", y=\"Rsq\", hue=\"Marker Gene\")\n",
    "plt.ylabel('R-squared', fontsize=12)\n",
    "plt.xlabel('Size fraction against total', fontsize=12)\n",
    "\n",
    "plt.savefig('outputs/'+'_rsq_both.png', dpi=200, bbox_inches=\"tight\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Calculate log2 fold change per feature at the phylum level of abundance between size fractions to identify which taxonomic group is driving the simple regression off x=y"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#add pseudo count for log-calculations and zero divisions\n",
    "slwplot['SL'] = slwplot['SL'] + 0.0000001\n",
    "slwplot['W'] = slwplot['W'] + 0.0000001\n",
    "\n",
    "#calculate log2 fold change\n",
    "slwplot['OR'] = (slwplot['W'] - slwplot['SL']) / slwplot['SL']\n",
    "slwplot['fold_change'] = slwplot['W']/slwplot['SL']\n",
    "slwplot['log2_fold_change'] = np.log2(slwplot['fold_change'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#make dual plot of log2FC and mean relative abundances side by side including error bars in the plots\n",
    "data = slwplot[['log2_fold_change','Phylum', 'W', 'SL']].copy()\n",
    "\n",
    "data['Phylum'] = data['Phylum'].map(lambda x: x.lstrip('p__'))\n",
    "\n",
    "# Group by index labels and take the means and standard deviations for each group\n",
    "data['avg_W'] = data['W'].groupby(data['Phylum']).transform('mean')\n",
    "data['std_W'] = data['W'].groupby(data['Phylum']).transform('std')\n",
    "data['avg_SL'] = data['SL'].groupby(data['Phylum']).transform('mean')\n",
    "data['std_SL'] = data['SL'].groupby(data['Phylum']).transform('std')\n",
    "data['means'] = data['log2_fold_change'].groupby(data['Phylum']).transform('mean')\n",
    "data['stds'] = data['log2_fold_change'].groupby(data['Phylum']).transform('std')\n",
    "\n",
    "data['positive'] = data['means'] > 0\n",
    "\n",
    "fig, axes = plt.subplots(ncols=2, sharey=True, figsize=(8, 10))\n",
    "\n",
    "axes[0].barh(data['Phylum'], data['means'],\n",
    "         xerr = data['stds'],\n",
    "         error_kw=dict(lw=0.5, capsize=1, capthick=0.5),\n",
    "         color=data.positive.map({True: 'g', False: 'r'}))\n",
    "\n",
    "axes[1].barh(data['Phylum'], data['avg_W'],\n",
    "            xerr = data['std_W'],\n",
    "         error_kw=dict(lw=0.5, capsize=1, capthick=0.5))\n",
    "\n",
    "#axes[2].barh(data['Phylum'], data['avg_SL'],\n",
    "#            xerr = data['std_SL'],\n",
    "#         error_kw=dict(lw=0.5, capsize=1, capthick=0.5))\n",
    "\n",
    "plt.gca().invert_yaxis()\n",
    "\n",
    "\n",
    "plt.savefig('outputs/'+comm_id+'/log2foldchange_d'+str(depth)+'.png', bbox_inches='tight', dpi=300)\n",
    "\n",
    "#plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#bar plot of log2FC per phylum without error bars\n",
    "data = slwplot[['log2_fold_change','Phylum']].copy()\n",
    "data['Phylum'] = data['Phylum'].map(lambda x: x.lstrip('p__'))\n",
    "\n",
    "# Group by index labels and take the means and standard deviations for each group\n",
    "#data['means'] = data['log2_fold_change'].groupby(data['Phylum']).transform('mean')\n",
    "#data['stds'] = data['log2_fold_change'].groupby(data['Phylum']).transform('std')\n",
    "\n",
    "data['positive'] = data['log2_fold_change'] > 0\n",
    "\n",
    "plt.figure(figsize=(6,11))\n",
    "plt.barh(data['Phylum'], data['log2_fold_change'],\n",
    "         color=data.positive.map({True: 'g', False: 'r'}))\n",
    "plt.gca().invert_yaxis()\n",
    "\n",
    "plt.savefig('outputs/'+comm_id+'/log2foldchange_d'+str(depth)+'_noerr.png', bbox_inches='tight', dpi=300)\n",
    "\n",
    "#plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "not_in_W = slwplot.loc[slwplot['W'] == 0]\n",
    "#not_in_W['feature_id'].nunique()\n",
    "not_in_W_from_S = not_in_W.loc[not_in_W['L'] == 0]\n",
    "#not_in_W_from_S['feature_id'].nunique()\n",
    "\n",
    "#calculate the percentage of features coming from the small size fraction that are absent from the whole  \n",
    "not_in_W_from_S['feature_id'].nunique()/not_in_W['feature_id'].nunique()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "sns.scatterplot(data=not_in_W, x='S', y='SL', hue='weekn')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### run lmplot for each pair of sets"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#loglog plot\n",
    "depths = [1,5,10,30,60]\n",
    "\n",
    "for depth in depths:\n",
    "    d1 = newseparated.loc[newseparated['depth'] == depth]\n",
    "    forpl = d1[['ratio', 'feature_id', 'sampleid', 'weekn', 'depth', 'size_code', 'Phylum']].copy()\n",
    "    slwplot = forpl.pivot_table(index=[\"feature_id\", \"depth\", 'weekn', 'Phylum'], columns=\"size_code\", values='ratio').fillna(0)\n",
    "    slwplot = slwplot.reset_index()\n",
    "    sns.set_style(\"white\")\n",
    "\n",
    "    #slwplot = slwplot.loc[slwplot['weekn'] = 10]\n",
    "    #slwplot = slwplot.loc[slwplot['weekn'] = 11]\n",
    "\n",
    "    slwplot = slwplot.rename(columns={\"depth\": \"Depth\"})\n",
    "    slwplot[\"weekn\"] = pd.to_numeric(slwplot[\"weekn\"])\n",
    "    g = sns.scatterplot(x=\"W\", y=\"SL\", data=slwplot, palette=['black'])#, hue='Phylum', alpha=0.6) #, hue=\"weekn\");\n",
    "    \n",
    "    #uncomment for log-log\n",
    "    #ax.set(xscale=\"log\", yscale=\"log\")\n",
    "    g.set_ylabel(\"Defractionated\",fontsize=15)\n",
    "    g.set_xlabel(\"Unfractionated\",fontsize=15)\n",
    "    g.tick_params(labelsize=12)\n",
    "    #g.legend(loc='center left', bbox_to_anchor=(1.25, 0.5), ncol=3)\n",
    "    plt.legend([],[], frameon=False)\n",
    "    \n",
    "    #plt.savefig('outputs/lmplot_'+comm+str(depth)+'WSL.png', bbox_inches='tight', dpi=300)\n",
    "\n",
    "    plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Phylogenetic analysis: taxonomic bar plots of relative abundance per depth and size fraction"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "if comm == 'chloroplast':\n",
    "    level = 'PRTaxon'\n",
    "else:\n",
    "    level = 'Genus'\n",
    "    \n",
    "table = newseparated\n",
    "#get a list of top taxa to provide the palette for the visualisation\n",
    "toptaxa = table[['feature_frequency', 'Taxon', 'size_code', 'depth','weekn', level]].copy()\n",
    "toptaxa = toptaxa.drop_duplicates()\n",
    "df_agg = toptaxa.groupby(['size_code',level, 'depth']).agg({'feature_frequency':sum})\n",
    "topd = df_agg['feature_frequency'].groupby(['size_code', 'depth'], group_keys=False).nlargest(3)\n",
    "topd = topd.to_frame()\n",
    "topd = topd.reset_index()\n",
    "listoftop = topd[level].unique()\n",
    "\n",
    "#set a palette for the toptaxa\n",
    "hex_colors_dic = {}\n",
    "rgb_colors_dic = {}\n",
    "hex_colors_only = []\n",
    "for name, hex in matplotlib.colors.cnames.items():\n",
    "    hex_colors_only.append(hex)\n",
    "    hex_colors_dic[name] = hex\n",
    "    rgb_colors_dic[name] = matplotlib.colors.to_rgb(hex)\n",
    "    \n",
    "palette_dict = {taxon: color for taxon, color in zip(listoftop, px.colors.sequential.Plasma)}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "phyld, top10d = taxbarplot(table, level, 1, 3, palette_dict, 'size_code')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "phyld.to_csv('feature_id_proks_1m_top3.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import plotly.io as pio\n",
    "pio.renderers.default = 'iframe' # or 'notebook' or 'colab' or 'jupyterlab'"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Top taxon longitudinal analysis"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "sfd=newseparated\n",
    "if comm == 'chloroplast':\n",
    "    level = 'PRSpecies'\n",
    "else:\n",
    "    level = 'Genus'\n",
    "toptaxa = sfd[['feature_id', 'feature_frequency', 'Taxon', 'size_code', 'depth','weekn']].copy()\n",
    "toptaxa = toptaxa.drop_duplicates()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "toptaxa['Genus'] = toptaxa['Taxon'].str.split('s__').str[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "sfd=newseparated\n",
    "if comm == 'chloroplast':\n",
    "    level = 'PRSpecies'\n",
    "else:\n",
    "    level = 'Genus'\n",
    "toptaxa = sfd[['feature_id', 'feature_frequency', 'Taxon', 'size_code', 'depth','weekn', level]].copy()\n",
    "toptaxa = toptaxa.drop_duplicates()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_agg = toptaxa.groupby(['size_code',level, 'depth', 'weekn']).agg({'feature_frequency':sum})\n",
    "topd = df_agg['feature_frequency'].groupby(['size_code', 'depth','weekn'], group_keys=False).nlargest(1)\n",
    "topd = topd.to_frame()\n",
    "topd = topd.reset_index()\n",
    "topd['Genus'].unique()\n",
    "\n",
    "#if looking at groups of top\n",
    "#newdf = topd.groupby(['size_code', 'depth','weekn'])[level].apply(lambda x: list(set(x)))\n",
    "#newdf = newdf.reset_index()\n",
    "\n",
    "#result = newdf.copy()\n",
    "\n",
    "#result = newdf.Genus.sort_values().apply(lambda x: sorted(x))\n",
    "#result = pd.DataFrame(result).reset_index(drop=True)\n",
    "\n",
    "#result['liststring'] = result[level].apply(lambda x: ','.join(map(str, x)))\n",
    "#result['liststring'].unique()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "type_dic={'d__Bacteria; p__Planctomycetota; c__OM190; o__OM190; f__OM190; g__OM190; ':9,\n",
    "       'd__Bacteria; p__Bacteroidota; c__Bacteroidia; o__Flavobacteriales; f__Flavobacteriaceae; g__Ulvibacter; ':1,\n",
    "       'd__Bacteria; p__Proteobacteria; c__Gammaproteobacteria; o__Salinisphaerales; f__Solimonadaceae; g__Polycyclovorans; ':6,\n",
    "       'd__Bacteria; p__Proteobacteria; c__Gammaproteobacteria; o__Alteromonadales; f__Alteromonadaceae; g__Alteromonas':16,\n",
    "       'd__Archaea; p__Crenarchaeota; c__Nitrososphaeria; o__Nitrosopumilales; f__Nitrosopumilaceae; g__Candidatus_Nitrosopumilus':15,\n",
    "       'd__Bacteria; p__Bacteroidota; c__Bacteroidia; o__Flavobacteriales; f__Flavobacteriaceae; g__NS3a_marine_group':10,\n",
    "       'd__Bacteria; p__Proteobacteria; c__Alphaproteobacteria; o__SAR11_clade; f__Clade_I; g__Clade_Ia':14,\n",
    "       'd__Bacteria; p__Proteobacteria; c__Alphaproteobacteria; o__Rhodobacterales; f__Rhodobacteraceae; g__Sulfitobacter':4,\n",
    "       'd__Bacteria; p__Bacteroidota; c__Bacteroidia; o__Flavobacteriales; f__Flavobacteriaceae; g__Polaribacter':7,\n",
    "       'd__Bacteria; p__Proteobacteria; c__Alphaproteobacteria; o__Rhodobacterales; f__Rhodobacteraceae; g__Planktomarina':8,\n",
    "       'd__Bacteria; p__Proteobacteria; c__Gammaproteobacteria; o__Thiomicrospirales; f__Thioglobaceae; g__SUP05_cluster':3,\n",
    "       'd__Bacteria; p__Bacteroidota; c__Bacteroidia; o__Flavobacteriales; f__Crocinitomicaceae; g__Fluviicola':12,\n",
    "       'd__Bacteria; p__Nitrospinota; c__Nitrospinia; o__Nitrospinales; f__Nitrospinaceae; g__LS-NOB':11,\n",
    "       'd__Bacteria; p__Proteobacteria; c__Gammaproteobacteria; o__Thiomicrospirales; f__Thioglobaceae':2,\n",
    "       'd__Bacteria; p__Proteobacteria; c__Gammaproteobacteria; o__Alteromonadales; f__Colwelliaceae; g__Colwellia':13,\n",
    "       'd__Bacteria; p__Proteobacteria; c__Gammaproteobacteria; o__Pseudomonadales; f__Pseudomonadaceae; g__Pseudomonas':5}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "Alteromonas\n",
    "Candidatus_Nitrosopumilus\n",
    "Clade_Ia\n",
    "Colwellia\n",
    "Fluviicola\n",
    "LS-NOB\n",
    "NS3a_marine_group\n",
    "OM190\n",
    "Planktomarina\n",
    "Polaribacter\n",
    "Polycyclovorans\n",
    "Pseudomonas\n",
    "Sulfitobacter\n",
    "SUP05_cluster\n",
    "Thioglobaceae\n",
    "Ulvibacter"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "type_dic_old = {'g__Alteromonas':1, 'g__Candidatus_Nitrosopumilus':2, 'g__Clade_Ia':3,\n",
    "       'g__Colwellia':4, 'g__Fluviicola':5, 'g__NS3a_marine_group':6,\n",
    "       'g__OM190':7, 'g__Planktomarina':8, 'g__Polaribacter':9,\n",
    "       'g__Polycyclovorans':10, 'g__Pseudomonas':11, 'g__SUP05_cluster':12,\n",
    "       'g__Sulfitobacter':13, 'g__Ulvibacter':14, 'g__uncultured':15}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "type_dic = {'Unassigned':15, 'g__Alteromonas':14, 'g__Candidatus_Nitrosopumilus':13,\n",
    "       'g__Clade_Ia':12, 'g__Colwellia':11, 'g__Fluviicola':10,\n",
    "       'g__NS3a_marine_group':9, 'g__OM190':8, 'g__Planktomarina':7,\n",
    "       'g__Polaribacter':6, 'g__Polycyclovorans':5, 'g__Pseudomonas':4,\n",
    "       'g__Sulfitobacter':3, 'g__Ulvibacter':2, 'g__uncultured':1}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#only if multiple organimsms in top ocmmunity \n",
    "result['comm_type'] = ''\n",
    "\n",
    "for tx, ctype in type_dic.items():\n",
    "    result.loc[result['liststring'] == tx, 'comm_type'] = ctype\n",
    "topd = result.copy()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#list the unique top taxa\n",
    "topd[level].unique()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "type_dic = {'Teleaulax':1, 'Thalassiosira':2, 'Chaetoceros':3, 'Unassigned':4,\n",
    "       'Eutreptiella':5, 'Micromonas':6, 'Phaeocystis':7,\n",
    "       'uncultured+bacterium':8, 'Haptolina':9, 'Chrysochromulina':10}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "type_dic = {\n",
    "    #\"c__Cyanobacteriia\": 1,\n",
    "    \"c__OM190\": 3,\n",
    "    \"c__Bacteroidia\": 2,\n",
    "    \"c__Gammaproteobacteria\": 5,\n",
    "    \"c__Alphaproteobacteria\": 4}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "topd['comm_type'] = ''\n",
    "\n",
    "for tx, ctype in type_dic.items():\n",
    "    topd.loc[topd[level] == tx, 'comm_type'] = ctype"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "topd[\"sc_weekn\"] = topd[\"depth\"].astype(str) + topd[\"size_code\"]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "topd = topd.sort_values(['depth', 'size_code'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "topdlist = topd['sc_weekn'].tolist()\n",
    "\n",
    "def uniqlist(seq):\n",
    "    seen = set()\n",
    "    seen_add = seen.add\n",
    "    return [x for x in seq if not (x in seen or seen_add(x))]\n",
    "\n",
    "mylist = uniqlist(topdlist)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "glue = topd.pivot(index=\"sc_weekn\", columns=\"weekn\", values=\"comm_type\")\n",
    "glue = glue.reindex(mylist)\n",
    "glue = glue[glue.columns].astype(float)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "cmap = plt.get_cmap('tab20', 16)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "sns.set_style('ticks')\n",
    "plt.figure(figsize=(5, 5))\n",
    "\n",
    "\n",
    "ax = sns.heatmap(glue, fmt='f', yticklabels=True, linewidths=.5, cmap=cmap)\n",
    "ax.axhline(4, ls='--')\n",
    "ax.axhline(8, ls='--')\n",
    "ax.axhline(12, ls='--')\n",
    "ax.axhline(16, ls='--')\n",
    "\n",
    "ax.set_xticks(range(0, 16, 5))\n",
    "\n",
    "plt.savefig('outputs/'+comm+'/heatmap_top1_16s_genus.png', bbox_inches='tight', dpi=300)\n",
    "\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Longitudinal analysis of top 1 taxa for eukaryotes (more than 20 groups)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Run these lines only for the 18S rRNA analysis"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "sfd=newseparated\n",
    "if comm == 'chloroplast':\n",
    "    level = 'PRSpecies'\n",
    "else:\n",
    "    level = 'Genus'\n",
    "toptaxa = sfd[['feature_id', 'feature_frequency', 'Taxon', 'size_code', 'depth','weekn']].copy()\n",
    "toptaxa = toptaxa.drop_duplicates()\n",
    "toptaxa['Genus'] = toptaxa['Taxon'].str.split('s__').str[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_agg = toptaxa.groupby(['size_code',level, 'depth', 'weekn']).agg({'feature_frequency':sum})\n",
    "topd = df_agg['feature_frequency'].groupby(['size_code', 'depth','weekn'], group_keys=False).nlargest(1)\n",
    "topd = topd.to_frame()\n",
    "topd = topd.reset_index()\n",
    "topd['Genus'].unique()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#18S has many more classes as top values to\n",
    "top518s = topd['Genus'].value_counts()[:19].index.tolist()\n",
    "\n",
    "topd.loc[~topd[\"Genus\"].isin(top518s), \"Genus\"] = \"Other\"\n",
    "\n",
    "#if looking at groups of top\n",
    "newdf = topd.groupby(['size_code', 'depth','weekn'])[level].apply(lambda x: list(set(x)))\n",
    "newdf = newdf.reset_index()\n",
    "\n",
    "result = newdf.copy()\n",
    "\n",
    "result = newdf.Genus.sort_values().apply(lambda x: sorted(x))\n",
    "result = pd.DataFrame(result).reset_index(drop=True)\n",
    "\n",
    "result['liststring'] = result[level].apply(lambda x: ','.join(map(str, x)))\n",
    "\n",
    "result['liststring'].unique()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "Other (Prymnesiales, Thalassiosira, Ploimida, Cydippida, Thecofilosea uncultured, d_Eukaryota,Cyclopoida\n",
    "      MAST-2, o_Syndiniales, Mitochondria, Choreotrichia uncultured, Amoebophrya, g__Pelagostrobilidium \n",
    "       g__Oxytrichidae\n",
    "       g__Spirotontonia g__MAST-1A g__Cryptocaryon g__Caecitellus g__Capitellida o__Helotiales \n",
    "       c__Dothideomycetes\n",
    "       g__Leptothecata o__Pucciniales p__Prymnesiophyceae g__Haplozoon g__MAST-7A g__Pithites\n",
    "Unassigned\n",
    "Bathycoccus\n",
    "Calanoida\n",
    "Chaetoceros\n",
    "Choreotrichia uncultured\n",
    "Dinophyceae\n",
    "Filobasidium\n",
    "Gymnodiniphycidae\n",
    "Hymenoptera\n",
    "Magnoliophyta\n",
    "Oligotrichia\n",
    "Phaeocystis\n",
    "Pucciniaceae\n",
    "Spirotrichea\n",
    "Strombidium\n",
    "Syndiniales GroupI\n",
    "Syndiniales uncultured\n",
    "Teleaulax\n",
    "Trachymedusae"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "type_dic = {'Other':20, 'Unassigned':19,\n",
    "       'd__Eukaryota; p__Arthropoda; c__Insecta; o__Hymenoptera; f__Hymenoptera; g__Hymenoptera':11,\n",
    "       'd__Eukaryota; p__Arthropoda; c__Maxillopoda; o__Calanoida; f__Calanoida; g__Calanoida':17,\n",
    "       'd__Eukaryota; p__Basidiomycota; c__Pucciniomycetes; o__Pucciniales; f__Pucciniaceae':7,\n",
    "       'd__Eukaryota; p__Basidiomycota; c__Tremellomycetes; o__Filobasidiales; f__Filobasidiaceae; g__Filobasidium':13,\n",
    "       'd__Eukaryota; p__Chlorophyta; c__Mamiellophyceae; o__Mamiellales; f__Mamiellales; g__Bathycoccus; ':18,\n",
    "       'd__Eukaryota; p__Ciliophora; c__Intramacronucleata; o__Spirotrichea':6,\n",
    "       'd__Eukaryota; p__Ciliophora; c__Intramacronucleata; o__Spirotrichea; f__Choreotrichia; g__uncultured; ':15,\n",
    "       'd__Eukaryota; p__Ciliophora; c__Intramacronucleata; o__Spirotrichea; f__Oligotrichia':9,\n",
    "       'd__Eukaryota; p__Ciliophora; c__Intramacronucleata; o__Spirotrichea; f__Oligotrichia; g__Strombidium; ':5,\n",
    "       'd__Eukaryota; p__Cnidaria; c__Hydrozoa; o__Trachymedusae; f__Trachymedusae; g__Trachymedusae; ':1,\n",
    "       'd__Eukaryota; p__Cryptophyceae; c__Cryptophyceae; o__Cryptomonadales; f__Cryptomonadales; g__Teleaulax; ':2,\n",
    "       'd__Eukaryota; p__Diatomea; c__Mediophyceae; o__Mediophyceae; f__Mediophyceae; g__Chaetoceros':16,\n",
    "       'd__Eukaryota; p__Dinoflagellata; c__Dinophyceae':14,\n",
    "       'd__Eukaryota; p__Dinoflagellata; c__Dinophyceae; o__Gymnodiniphycidae':12,\n",
    "       'd__Eukaryota; p__Phragmoplastophyta; c__Embryophyta; o__Magnoliophyta; f__Magnoliophyta; g__Magnoliophyta; ':10,\n",
    "       'd__Eukaryota; p__Protalveolata; c__Syndiniales; o__Syndiniales; f__Syndiniales; g__uncultured; ':3,\n",
    "       'd__Eukaryota; p__Protalveolata; c__Syndiniales; o__Syndiniales; f__Syndiniales_Group_I; g__Syndiniales_Group_I; ':4,\n",
    "       'd__Eukaryota; p__Prymnesiophyceae; c__Prymnesiophyceae; o__Prymnesiophyceae; f__Prymnesiophyceae; g__Phaeocystis; ':8}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "type_dic_all18s = {'Unassigned':28, 'g__Amoebophrya':27, 'g__Bathycoccus':26, 'g__Caecitellus':25,\n",
    "       'g__Capitellida':24, 'g__Chaetoceros':23, 'g__Cryptocaryon':22,\n",
    "       'g__Cyclopoida':21, 'g__Cydippida':20, 'g__Filobasidium':19, 'g__Haplozoon':18,\n",
    "       'g__Hymenoptera':17, 'g__Leptothecata':16, 'g__MAST-7A':15,\n",
    "       'g__Magnoliophyta':14, 'g__Mitochondria':13, 'g__Oxytrichidae':12,\n",
    "       'g__Pelagostrobilidium':11, 'g__Phaeocystis':10, 'g__Ploimida':9,\n",
    "       'g__Spirotontonia':8, 'g__Spirotrichea':7, 'g__Strombidium':6,\n",
    "       'g__Syndiniales_Group_I':5, 'g__Teleaulax':4, 'g__Thalassiosira':3,\n",
    "       'g__Trachymedusae':2, 'g__uncultured':1}\n",
    "\n",
    "type_dic_old = {\n",
    "    'Other':20, 'Unassigned':19, 'g__Bathycoccus':18, 'g__Chaetoceros':17,\n",
    "       'g__Cydippida':16, 'g__Filobasidium':15, 'g__Hymenoptera':14,\n",
    "       'g__Leptothecata':13, 'g__Magnoliophyta':12, 'g__Oxytrichidae':11,\n",
    "       'g__Pelagostrobilidium':10, 'g__Phaeocystis':9, 'g__Ploimida':8,\n",
    "       'g__Spirotontonia':7, 'g__Spirotrichea':6, 'g__Strombidium':5,\n",
    "       'g__Syndiniales_Group_I':4, 'g__Teleaulax':3, 'g__Trachymedusae':2,\n",
    "       'g__uncultured:':1\n",
    "}\n",
    "\n",
    "#make a column for community type from the dictionary with only top1\n",
    "\n",
    "for tx, ctype in type_dic.items():\n",
    "    topd.loc[topd['Genus'] == tx, 'comm_type'] = ctype\n",
    "\n",
    "topd[\"sc_weekn\"] = topd[\"depth\"].astype(str) + topd[\"size_code\"]\n",
    "\n",
    "topd = topd.sort_values(['depth', 'size_code'])\n",
    "\n",
    "topdlist = topd['sc_weekn'].tolist()\n",
    "\n",
    "def uniqlist(seq):\n",
    "    seen = set()\n",
    "    seen_add = seen.add\n",
    "    return [x for x in seq if not (x in seen or seen_add(x))]\n",
    "\n",
    "mylist = uniqlist(topdlist)\n",
    "\n",
    "glue = topd.pivot(index=\"sc_weekn\", columns=\"weekn\", values=\"comm_type\")\n",
    "glue = glue.reindex(mylist)\n",
    "glue = glue[glue.columns].astype(float)\n",
    "cmap = plt.get_cmap('tab20', 20)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "sns.set_style('ticks')\n",
    "plt.figure(figsize=(5, 5))\n",
    "\n",
    "\n",
    "ax = sns.heatmap(glue, fmt='f', yticklabels=True, linewidths=.5, cmap=cmap)\n",
    "ax.axhline(4, ls='--')\n",
    "ax.axhline(8, ls='--')\n",
    "ax.axhline(12, ls='--')\n",
    "ax.axhline(16, ls='--')\n",
    "\n",
    "ax.set_xticks(range(0, 16, 5))\n",
    "\n",
    "\n",
    "plt.savefig('outputs/heatmap_'+comm+'top1class_reduced.png', bbox_inches='tight', dpi=300)\n",
    "\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "result.Class.apply(tuple).unique()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "topd['Class'].unique()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "type_dic = {'Other':5, 'c__Dinophyceae':1, 'c__Mediophyceae':2,\n",
    "       'c__Intramacronucleata':3, 'c__Syndiniales':4}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#use this dic if looking at community type by 3 top taxa\n",
    "type_dic = {'c__Bacteroidia,c__Cyanobacteriia,c__OM190':1,\n",
    "       'c__Gammaproteobacteria,c__Bacteroidia,c__Cyanobacteriia':2,\n",
    "       'c__Alphaproteobacteria,c__Bacteroidia,c__Cyanobacteriia':3,\n",
    "       'c__Bacteroidia,c__Cyanobacteriia,c__Planctomycetes':4,\n",
    "       'c__Bacteroidia,c__Alphaproteobacteria,c__OM190':5,\n",
    "       'c__Bacteroidia,c__OM190,c__Planctomycetes':6,\n",
    "       'c__Gammaproteobacteria,c__Bacteroidia,c__OM190':7,\n",
    "       'c__Gammaproteobacteria,c__Bacteroidia,c__Planctomycetes':8,\n",
    "       'c__Cyanobacteriia,c__OM190,c__Planctomycetes':9,\n",
    "       'c__Alphaproteobacteria,c__Gammaproteobacteria,c__Cyanobacteriia':10,\n",
    "       'c__Gammaproteobacteria,c__Bacteroidia,c__Alphaproteobacteria':11,\n",
    "       'c__Bacteroidia,c__Alphaproteobacteria,c__Cyanobacteriia':12,\n",
    "       'c__Nitrososphaeria,c__Gammaproteobacteria,c__Bacteroidia':13,\n",
    "       'c__Gammaproteobacteria,c__Alphaproteobacteria':14,\n",
    "       'c__Cyanobacteriia':15}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#make column communty type from top 2,3,...\n",
    "result['comm_type'] = ''\n",
    "\n",
    "for tx, ctype in type_dic.items():\n",
    "    result.loc[result['liststring'] == tx, 'comm_type'] = ctype\n",
    "    \n",
    "result\n",
    "topd = result.copy()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Taxonomy plotting"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "    sfd=separated[separated.depth==depth]\n",
    "    toptaxa = sfd[['feature_id', 'feature_frequency', 'Taxon', 'size_code', 'depth','weekn', level]].copy()\n",
    "    toptaxa = toptaxa.drop_duplicates()\n",
    "    df_agg = toptaxa.groupby(['size_code',level, 'depth']).agg({'feature_frequency':sum})\n",
    "    topd = df_agg['feature_frequency'].groupby('size_code', group_keys=False).nlargest(topn)\n",
    "    topd = topd.to_frame()\n",
    "    topd = topd.reset_index()\n",
    "\n",
    "\n",
    "    df_agg = df_agg.reset_index()\n",
    "    df_agg['set_name'] = df_agg['size_code']+df_agg['depth'].astype(str)\n",
    "    \n",
    "    cumulab = separated[['feature_frequency', 'depth', 'size_code', 'Genus']].copy()\n",
    "    cumulab1 = cumulab.groupby(['Genus']).agg({'feature_frequency':sum})\n",
    "\n",
    "    resultpivot = df_agg.pivot_table(index=level, columns='set_name', values='feature_frequency')\n",
    "    resultpivot = resultpivot.fillna(0)\n",
    "    resultpivot[resultpivot != 0] = 1\n",
    "    tosave = pd.merge(resultpivot, cumulab1, left_index=True, right_index=True)\n",
    "    tosave.to_csv(level+'_'+str(depth)+'16S_relab.csv')\n",
    "    \n",
    "    top10d_list = topd[level].unique()\n",
    "    top10d = sfd.copy()\n",
    "    top10d.loc[~top10d[level].isin(top10d_list), level] = 'Other' #isnot in top list\n",
    "    phyld = top10d.groupby(['size_code','weekn', level])['ratio'].sum()\n",
    "    phyld = phyld.reset_index()\n",
    "\n",
    "\n",
    "    fig = px.bar(phyld, x=\"size_code\", y=\"ratio\", facet_col=\"weekn\", color=level, labels={\n",
    "                     \"feature_frequency\": \"Relative abundance\",\n",
    "                     \"size_code\": \"\",\n",
    "                     \"weekn\": \"w\"}, color_discrete_map=palette_dict)\n",
    "    fig.update_xaxes(type='category', dtick=1)\n",
    "    fig.update_layout(\n",
    "        title=\"Relative abundance of top 10\" + level + 'observed at Depth' + str(depth),\n",
    "        yaxis_title=\"Relative abundance\",\n",
    "        xaxis_title=\"Size fraction\",\n",
    "        legend_title=level,\n",
    "        font=dict(size=8)\n",
    "    )\n",
    "\n",
    "    fig.show()\n",
    "    #fig.write_image(\"outputs/fig1.png\")\n",
    "    #fig.to_image(format=\"png\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "phyld, top10d = taxbarplot(newseparated, 'Class', 5, 5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plot_df2 = plot_df2.drop_duplicates()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plot_df3 = plot_df2.set_index('sampleid')\n",
    "plot_df3"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "permanova2 = permanova(dm, plot_df3, 'Size code')\n",
    "permanova2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "pca, pca_features, sfdclr, dm = pcaplot(table, 60, comm, 'size_code', 'DFr', 'week')\n",
    "distance_matrix2 = distance_matrix.reset_index()\n",
    "idedup = distance_matrix2['samples'].to_list()\n",
    "dm = DistanceMatrix(distance_matrix, ids=idedup)\n",
    "df123 = dm.to_data_frame()\n",
    "df123.to_csv('distance_matrix_5m16s.tsv', sep='\\t')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "distance_matrix2 = distance_matrix.reset_index()\n",
    "idedup = distance_matrix2['samples'].to_list()\n",
    "dm = DistanceMatrix(distance_matrix, ids=idedup)\n",
    "df123 = dm.to_data_frame()\n",
    "df123.to_csv('distance_matrix_5m16s.tsv', sep='\\t')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df123.to_csv('distance_matrix_5m16s.tsv', sep='\\t')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plot_df2.to_csv('METADATAtiny.txt', sep='\\t')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "pca, pca_features, sfdclr, dm = pcaplot(onlyDFRW, 'all', comm, 'Size code', 'DFr', 'week')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "newdm = dm.stack().reset_index().sort_values(0)\n",
    "newdm = newdm[newdm['samples'] != newdm['sampleid']]\n",
    "newdm[\"depth_codes\"] = newdm[\"samples\"].str.extract(r'[1-9][0-9]?([A-E])')\n",
    "newdm[\"depth_code\"] = newdm[\"sampleid\"].str.extract(r'[1-9][0-9]?([A-E])')\n",
    "newdm[\"weeknsamples\"] = newdm[\"samples\"].str.extract(r'\\.([1-9][0-9]?)[A-E]')\n",
    "newdm[\"weeknsampleid\"] = newdm[\"sampleid\"].str.extract(r'\\.([1-9][0-9]?)[A-E]')\n",
    "newdm = newdm[newdm['weeknsampleid'] == newdm['weeknsamples']]\n",
    "newdm = newdm[newdm['depth_codes'] == newdm['depth_code']]\n",
    "newdm.to_csv('outputs/'+comm+'/compareall.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "sns.set_style('ticks')\n",
    "newdm['weeknsamples'] = pd.to_numeric(newdm['weeknsamples'])\n",
    "\n",
    "g=sns.lineplot(data=newdm, x=\"weeknsamples\", y=0, hue=\"depth_codes\", hue_order = ['A', 'B', 'C', 'E', 'D'],\n",
    "              palette=sns.color_palette(\"Blues\"))\n",
    "sns.move_legend(g,\"upper left\", bbox_to_anchor=(1, 1), title='Depth')\n",
    "g.set(xlabel='Time(weeks)', ylabel='Euclidean distance', title=comm)\n",
    "\n",
    "plt.savefig('outputs/'+comm+'/eucldist.png', dpi=200, bbox_inches=\"tight\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "! conda install bioconda::bioconductor-aldex2 --yes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "newmetadata = newseparated[['sampleid', 'weekn', 'size_code', 'depth', 'depth_code', 'month_name']].copy()\n",
    "newmetadata = newmetadata.drop_duplicates()\n",
    "newmetadata.to_csv('METADATA.tsv', sep='\\t')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "pca_features"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from skbio.stats.distance import permanova"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Stacked bar plots"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "comm"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "level = 'Phylum'\n",
    "if level == 'feature_id':\n",
    "    id = 'ASV'\n",
    "else:\n",
    "    id = level\n",
    "\n",
    "subtitile = 'subtitle'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "dfplot, level = calcperc(comm, separated, level)\n",
    "# variables\n",
    "labels = ['S', 'L','S  L', 'W', 'W  (S  L)']\n",
    "colors = ['#5975a4','#d55e00','#D39473', '#6EAF46', '#9F946E']\n",
    "title = 'Weighted proportion of shared '+id+' between size fractionated and non size fractionated samples'\n",
    "\n",
    "plot_stackedbar_p(comm, dfplot, labels, colors, title, subtitle, level)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "sfd=separated[separated.depth==1]\n",
    "toptaxa = sfd[[level, 'feature_frequency', 'Taxon', 'size_code', 'weekn']].copy()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "toptaxa = toptaxa.drop_duplicates()\n",
    "df_agg = toptaxa.groupby(['size_code',level]).agg({'feature_frequency':sum})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_agg = df_agg.reset_index()\n",
    "resultpivot = df_agg.pivot_table(index=level, columns='size_code', values='feature_frequency')\n",
    "resultpivot = resultpivot.fillna(0)\n",
    "df = resultpivot.copy()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "Sonly = df[(df['L'] == 0) & (df['W'] == 0)]\n",
    "Wonly = df[(df['L'] == 0) & (df['S'] == 0)]\n",
    "Lonly = df[(df['S'] == 0) & (df['W'] == 0)]\n",
    "LW = df[(df['S'] == 0) & (df['W'] != 0) & (df['L'] != 0)]\n",
    "LS = df[(df['W'] == 0) & (df['S'] != 0) & (df['L'] != 0)]\n",
    "SW = df[(df['W'] != 0) & (df['S'] != 0) & (df['L'] == 0)]\n",
    "LSW = df[~(df == 0).any(axis=1)]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "dict = {'Sonly': Sonly.index.tolist(), 'Wonly': Wonly.index.tolist(), 'Lonly': Lonly.index.tolist(),\n",
    "        'LW': LW.index.tolist(), 'LS':LS.index.tolist(), 'SW':SW.index.tolist(), 'LSW':LSW.index.tolist()}\n",
    "D_taxlist = pd.DataFrame.from_dict({'Sonly': Sonly.index.tolist(), 'Wonly': Wonly.index.tolist(), 'Lonly': Lonly.index.tolist(),\n",
    "        'LW': LW.index.tolist(), 'LS':LS.index.tolist(), 'SW':SW.index.tolist(), 'LSW':LSW.index.tolist()}, orient='index').T\n",
    "\n",
    "D_taxlist.to_csv('outputs/'+comm+'/'+str(depth)+'_taxlist.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "sfd=separated[separated.depth==depths[d]]\n",
    "toptaxa = sfd[[level, 'feature_frequency', 'Taxon', 'size_code', 'weekn']].copy()\n",
    "\n",
    "        toptaxa = toptaxa.drop_duplicates()\n",
    "        df_agg = toptaxa.groupby(['size_code',level]).agg({'feature_frequency':sum})\n",
    "\n",
    "        df_agg = df_agg.reset_index()\n",
    "        resultpivot = df_agg.pivot_table(index=level, columns='size_code', values='feature_frequency')\n",
    "        resultpivot = resultpivot.fillna(0)\n",
    "\n",
    "        df = resultpivot.copy()\n",
    "\n",
    "        Sonly = df[(df['L'] == 0) & (df['W'] == 0)]\n",
    "        Wonly = df[(df['L'] == 0) & (df['S'] == 0)]\n",
    "        Lonly = df[(df['S'] == 0) & (df['W'] == 0)]\n",
    "        LW = df[(df['S'] == 0) & (df['W'] != 0) & (df['L'] != 0)]\n",
    "        LS = df[(df['W'] == 0) & (df['S'] != 0) & (df['L'] != 0)]\n",
    "        SW = df[(df['W'] != 0) & (df['S'] != 0) & (df['L'] == 0)]\n",
    "        LSW = df[~(df == 0).any(axis=1)]\n",
    "\n",
    "        dict = {'Sonly': Sonly, 'Wonly': Wonly, 'Lonly': Lonly, 'LW': LW, 'LS':LS, 'SW':SW, 'LSW':LSW}\n",
    "        D_taxlist = pd.DataFrame(dict, index=[0])\n",
    "        D_taxlist.to_csv('outputs/'+comm+'/'+str(depth)+'_taxlist.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "dfplot16s = dfplot.copy()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "dfplot18s = dfplot.copy()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "newchl = dfplotchloro/3"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "new18 = dfplot18s/3"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "new16 = dfplot16s/3"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "newdfplot = newchl+new18+new16"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "new18"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "new16"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "newchl"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "dfplot18s"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "dfplotSLNSF"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "data = {'Depth':['1','5','10','30','60'],\n",
    "    'Sonly': [3, 3, 3, 2.644278, 3],\n",
    "        'Lonly': [0, 0, 0, 0.4, 0],\n",
    "        'LS': [0, 0, 0, 0,0],\n",
    "       'NSF': [0, 0, 0, 0,0]}\n",
    "dfplotSLNSF = pd.DataFrame(data)\n",
    "dfplotSLNSF2 = dfplotSLNSF.set_index('Depth')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "dfplotSLNSF2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "dfplotSLNSF, dfplot_normalized, level = calcperc_SLNSF(comm, newseparated, level)\n",
    "# variables\n",
    "labels = ['S', 'L','S  L', 'W']\n",
    "colors = ['#5975a4','#d55e00','#D39473', '#6EAF46']\n",
    "title = 'Weighted proportion of shared '+ id +' between size fractionated and non size fractionated samples'\n",
    "\n",
    "plot_stackedbar_p_SLNSF(comm, dfplotSLNSF, labels, colors, title, subtitle, level, 30.1, 5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "newbiom = d1.pivot_table(index=\"feature_id\", columns=\"sampleid\", values=\"feature_frequency\")\n",
    "newbiom = newbiom.fillna(0)\n",
    "newbiom.to_csv('newbiomdepth1.tsv', sep=\"\\t\") "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 16S ANCOM PER DEPTH"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "** another idea is to run ancom of sizefraction specific and compare after the categories (run ancom on ?time or month.. or some other column) and compare the number/taxonomy of differentially abundant taxa recovered;\n",
    "are we recovering the same diff ab taxa between the (1.SF samples, 2. NSF samples)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#uncomment if you want to exclude the Large size fraction from the ANCOM\n",
    "#onlyDFRW = newseparated[newseparated.size_code != 'L']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "depth = 5\n",
    "pca, pca_features, sfdclr, dm = pcaplot(separated, depth, comm, 'size_code', 'DFr', 'week')\n",
    "DAresults, DARejected_SC_taxonomy, prcentile = run_ancom(comm, separated, sfdclr, depth, 'size_code')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "DAresults"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "topiv = onlyDFRW[['feature_id', 'feature_frequency', 'sampleid']].copy()\n",
    "topiv = topiv.drop_duplicates()\n",
    "\n",
    "sfdpiv= topiv.pivot(index='sampleid', columns='feature_id', values='feature_frequency')\n",
    "sfdpiv=sfdpiv.fillna(0)\n",
    "sfdclr=sfdpiv.mask(sfdpiv==0).fillna(0.1)\n",
    "clr_transformed_array = clr(sfdclr)\n",
    "samples = sfdpiv.index\n",
    "asvs = sfdpiv.columns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Creating the dataframe with the clr transformed data, and assigning the sample names\n",
    "clr_transformed = pd.DataFrame(clr_transformed_array, columns=asvs)\n",
    "#Assigning the asv names\n",
    "clr_transformed['samples'] = samples\n",
    "clr_transformed = clr_transformed.set_index('samples')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "clr_transformed.reset_index(inplace=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "clr_transformed[\"size_code\"] = clr_transformed[\"samples\"].str.extract(r'[1-9][0-9]?[A-E]([SL])')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "clr_transformed[\"size_code\"] = clr_transformed[\"size_code\"].fillna('W')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "clr_transformed = clr_transformed.melt(id_vars=['samples', 'size_code'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "clr_transformed['clrmean'] = clr_transformed.groupby(['size_code', 'feature_id']).transform('mean')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "clr_transformed.drop(['value', 'samples'], axis=1, inplace=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "clr_transformed = clr_transformed.drop_duplicates()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "clr_transformed.drop(['size_code'], axis=1, inplace=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "clr_transformed['clrdiff'] = clr_transformed.groupby(['feature_id']).transform('diff')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "clr_transformed.drop(['clrmean'], axis=1, inplace=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "clr_transformed = clr_transformed.drop_duplicates()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "clr_transformed.dropna(subset=[\"clrdiff\"], inplace=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "merged_df = pd.merge(DAresults, clr_transformed, on='feature_id')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "merged_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import plotly.express as px\n",
    "fig = px.scatter(merged_df, x=\"clrdiff\", y=\"W\", hover_name=\"Taxon\")#, hover_data=[\"continent\", \"pop\"])\n",
    "fig.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "comm"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "depths = [1,5,10,30,60]\n",
    "table = separated\n",
    "for depth in depths:\n",
    "    pca, pca_features, sfdclr, dm = pcaplot(table, depth, comm, 'size_code', 'DFr', 'week')\n",
    "    DAresults, DARejected_SC_taxonomy, prcentile = run_ancom(comm, table, sfdclr, depth, 'size_code')\n",
    "    DAresults.to_csv('outputs/'+comm+'/DARejected'+str(depth)+'.csv')\n",
    "    DARejected_SC_taxonomy.to_csv('outputs/'+comm+'/DARejected_SC_taxonomy'+str(depth)+'.csv')\n",
    "    prcentile.to_csv('outputs/'+comm+'/prcentile'+str(depth)+'.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "prcentile"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "dfL = prcentile.xs('L', axis=1, level=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "dfL['size_code']='L'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "dfS = prcentile.xs('S', axis=1, level=1)\n",
    "dfS['size_code']='S'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "new= pd.merge(dfL, dfS, on='feature_id')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import plotly.express as px\n",
    "df = px.data.iris()\n",
    "fig = px.scatter(df, x=\"sepal_width\", y=\"sepal_length\", color=\"species\", symbol=\"species\")\n",
    "fig.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "prcentile1_16 = prcentile1_16.reset_index()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "prcentile1_16.loc[prcentile1_16['feature_id'] == 'a955e3b357dd61bebe626bf1d0af33c4']"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Group-specific time series"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "fids = ['5a94578dd1d7cdd039a52f1c7079f874',\n",
    "'6a1d2131ef3ebebb7570e93c8c9982e1',\n",
    "'3ddb87be5f1e731b40012be7394d8e4e']\n",
    "depth = 1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "subplots(comm, depth, fids, 2, newseparated)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "save_individual_plots(comm,depth,fid,newseparated)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "save_all4_plots(comm,depth,fid,newseparated)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Permanova results from R into boxplots"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "permresu = pd.read_csv('R_results/post_hoc_results.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "permresu[\"depth_pairs\"] = permresu[\"depth\"].astype(str) + permresu[\"pairs\"]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "ax = sns.catplot(\n",
    "    permresu, kind=\"bar\",\n",
    "    x=\"p.adjusted\", y=\"pairs\", col=\"comm\", hue=\"depth\",\n",
    "    height=4, aspect=1.3, palette=\"Greys\", log=True\n",
    ")\n",
    "#ax.set(xlim=(0, 0.10))\n",
    "\n",
    "ax.refline(x=0.05, color='red')\n",
    "\n",
    "plt.savefig('outputs/perm_pvalues_logged.png', bbox_inches='tight', dpi=300)\n",
    "\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "ax = sns.catplot(\n",
    "    permresu, kind=\"bar\",\n",
    "    x=\"p.adjusted\", y=\"pairs\", col=\"comm\", hue=\"depth\",\n",
    "    height=4, aspect=1.3, palette=\"Greys\", log=True\n",
    ")\n",
    "#ax.set(xlim=(0, 0.10))\n",
    "\n",
    "ax.refline(x=0.05, color='red')\n",
    "\n",
    "plt.savefig('outputs/perm_pvalues_logged.png', bbox_inches='tight', dpi=300)\n",
    "\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "comm"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Random Forest"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "newsep2 = newseparated[newseparated.size_code != 'L']\n",
    "newsep2 = newsep2[newsep2.size_code != 'S']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "depth=60\n",
    "d_spc = newsep2[newsep2.depth== depth]\n",
    "new = run_RF(comm, depth, d_spc, newseparated)\n",
    "new['depth'] = depth"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "alldepths = pd.merge(alldepths, new,\n",
    "                     on=['depth', 'feature_id','Taxon', 'Domain', 'Phylum', 'Class', 'Order', 'Family', 'Genus', 'Species', 0],\n",
    "                    how='outer')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "alldepths.to_csv('top20predictorsperdepth_euks.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "alldepths.sort_values(0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df__new = alldepths.groupby('feature_id')['depth'].apply(list).reset_index(name='list_depths')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df__new['list_lengths']  = df__new['list_depths'].str.len()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df__new.sort_values('list_lengths')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "f_id = 'e28ef71120021f922b6c979bf673e5cc'\n",
    "newseparated.loc[newseparated['feature_id'] == f_id, 'Taxon'].tolist()[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "onlyher = newseparated.loc[newseparated['feature_id'] == f_id]\n",
    "sns.scatterplot(x='weekn', y='ratio', hue='size_code',data=onlyher, style=\"depth\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "scl = 'g__Syndiniales_Group_II'\n",
    "depth=30\n",
    "#if all size codes\n",
    "d_spc = newseparated[newseparated.depth == depth]\n",
    "\n",
    "#if only SL and W\n",
    "#d_spc = newsep2[newsep2.depth == depth]\n",
    "\n",
    "#d_spc_c = d_spc[d_spc.feature_id == f_id]\n",
    "d_spc_c = d_spc[d_spc.Genus == scl]\n",
    "\n",
    "sizecodes = ['S', 'L', 'W', 'SL', 'P']\n",
    "palette_colors = sns.color_palette()\n",
    "palette_dict = {sizecode: color for sizecode, color in zip(sizecodes, palette_colors)}\n",
    "        \n",
    "\n",
    "g = sns.lmplot(x=\"weekn\", y=\"ratio\", data=d_spc_c,\n",
    "           order=4, ci=None, scatter_kws={\"s\": 80}, hue='size_code', palette=palette_dict)\n",
    "\n",
    "plt.title(scl.split('__')[1] +', '+str(depth)+ 'm')\n",
    "#plt.title(scl +', '+str(depth)+ 'm')\n",
    "# Set x-axis label\n",
    "plt.xlabel('Time (weeks)')\n",
    "# Set y-axis label\n",
    "plt.ylabel('Relative abundance')\n",
    "#plt.ylabel('Rank')\n",
    "g.fig.set_size_inches(5,3.5)\n",
    "\n",
    "plt.savefig('outputs/'+comm+'/D'+str(depth)+scl+'_lmplot_allsyns.png', dpi=200, bbox_inches=\"tight\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "comm"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "depth=10\n",
    "\n",
    "#split by depth\n",
    "d_spc = newseparated[newseparated.depth == depth]\n",
    "\n",
    "#d_spc[['feature_id', 'ratio', 'Taxon','sampleid']].sort_values('ratio')\n",
    "\n",
    "d_spc = d_spc[d_spc.size_code != 'SL']\n",
    "newzie = d_spc[['feature_id', 'ratio', 'Taxon','Family' ,'Class', 'Genus', 'Species','size_code', 'feature_frequency']]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "newzie2 = d_spc[['feature_id', 'size_code']]\n",
    "newzie2.drop_duplicates(inplace=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#only get those that are not shared between S and W\n",
    "df_filtered = newzie2.groupby('feature_id').filter(lambda g: len(g) < 2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "ok = df_filtered.merge(newzie, on=['feature_id', 'size_code'], how='left').sort_values('feature_frequency')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "sizecodes = ['S', 'L', 'W', 'SL', 'P']\n",
    "palette_colors = sns.color_palette()\n",
    "palette_dict = {sizecode: color for sizecode, color in zip(sizecodes, palette_colors)}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "g=sns.displot(ok, x=\"ratio\", hue=\"size_code\", multiple=\"stack\", palette=palette_dict)\n",
    "plt.xlabel('Relative abundance')\n",
    "g.fig.set_size_inches(5,3.5)\n",
    "\n",
    "plt.savefig('outputs/'+comm+'/displot_'+str(depth)+'m_all.png', dpi=200, bbox_inches=\"tight\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "ok2 = ok[ok['ratio'] <= 0.005]  \n",
    "\n",
    "g=sns.displot(ok2, x=\"ratio\", hue=\"Class\", multiple=\"stack\"),# palette=palette_dict)\n",
    "plt.xlabel('Relative abundance')\n",
    "g.fig.set_size_inches(5,3.5)\n",
    "\n",
    "plt.savefig('outputs/'+comm+'/displot_'+str(depth)+'m_sml0.005.png', dpi=200, bbox_inches=\"tight\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "ok3 = ok[ok['ratio'] >= 0.005]  \n",
    "\n",
    "g=sns.displot(ok3, x=\"ratio\", hue=\"size_code\", multiple=\"stack\", palette=palette_dict)\n",
    "plt.xlabel('Relative abundance')\n",
    "g.set(ylim=(0, 300))\n",
    "g.fig.set_size_inches(5,3.5)\n",
    "\n",
    "plt.savefig('outputs/'+comm+'/displot_'+str(depth)+'m_lrg0.005.png', dpi=200, bbox_inches=\"tight\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "ok3.sort_values('ratio')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "ok3 = ok[ok['ratio'] >= 0.002]  "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "ok3.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "ok.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "1564-55"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "1509/1564 * 100"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "ok.sort_values('ratio')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "ok.groupby('Family').count().sort_values('feature_id')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "ok22 = ok[ok['Family'] == 'f__Flavobacteriaceae']  "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "g=sns.displot(ok22, x=\"ratio\", hue=\"size_code\", multiple=\"stack\", palette=palette_dict)\n",
    "plt.xlabel('Relative abundance')\n",
    "g.fig.set_size_inches(5,3.5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "d_spc = newseparated[newseparated.depth == depth]\n",
    "#d_spc[['feature_id', 'ratio', 'Taxon','sampleid']].sort_values('ratio')\n",
    "\n",
    "d_spc = d_spc[d_spc.size_code == 'L']\n",
    "\n",
    "newzie = d_spc[['feature_id', 'ratio', 'Taxon','sampleid', 'Genus', 'Species', 'rank', 'size_code']].nsmallest(100, 'ratio')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "d_spc = newseparated[newseparated.depth == depth]\n",
    "#d_spc[['feature_id', 'ratio', 'Taxon','sampleid']].sort_values('ratio')\n",
    "\n",
    "d_spc = d_spc[d_spc.size_code != 'SL']\n",
    "\n",
    "newzie = d_spc[['feature_id', 'ratio', 'Taxon','sampleid', 'Genus', 'Species', 'rank', 'size_code']].nlargest(75, 'ratio')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "sns.displot(newzie, x=\"size_code\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "d_spc = newseparated[newseparated.sampleid == 'BB22.12A']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "d_spc[['feature_frequency']]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "d_spc_c"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Feature selection based off chi square test \n",
    "code from https://github.com/gsampath127/Feature-Selection/blob/master/FeatureSelection_ChiSquareTest.ipynb"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as numpy\n",
    "import pandas as pd\n",
    "import seaborn as sns\n",
    "from sklearn.preprocessing import LabelEncoder"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "label_encoder = LabelEncoder()\n",
    "churn_df['Geography'] = label_encoder.fit_transform(churn_df['Geography'])\n",
    "churn_df['Gender'] = label_encoder.fit_transform(churn_df['Gender'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "qiime2-2023.5",
   "language": "python",
   "name": "qiime2-2023.5"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.16"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
