{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Upload functions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "from bb2022_functions import *\n",
    "%matplotlib inline\n",
    "from Bio.SeqIO.FastaIO import SimpleFastaParser\n",
    "from Bio import SeqIO\n",
    "pd.options.mode.chained_assignment = None  # default='warn'"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Import and format metadata from lab, and BBMP"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "md = pd.read_csv(\"metadata_merged.csv\")\n",
    "merged = pd.read_csv(\"metadata_niskin.csv\")\n",
    "all_md = pd.read_csv(\"allmetadata.csv\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "detect_anomalies('Temperature_y', all_md, 1, yr={2022}, month={1,2,3,4,5})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "d1 = all_md.loc[all_md['depth'] == 1]\n",
    "d1 = d1[['weekn', 'depth', 'Phosphate',\n",
    "       'Ammonia', 'Chlorophyll A']]\n",
    "d1.rename(columns={'Temperature_x': 'Temperature'},\n",
    "          inplace= True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "d1 = d1.melt(id_vars=['weekn', 'depth'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import seaborn as sns\n",
    "sns.set_theme(style=\"ticks\")\n",
    "\n",
    "# Plot the responses for different events and regions\n",
    "#ax = sns.lineplot(x=\"weekn\", y=\"value\", hue='variable',data=d1)\n",
    "\n",
    "ax1 = df.plot(y='value', c='k', figsize=(15, 6), grid=True, legend=False,\n",
    "              title='Adjusted Close with Regression Line from 2019-01-02')\n",
    "\n",
    "\n",
    "sns.regplot(data=data, x='Date', y='Adj Close', ax=ax1, color='magenta', scatter_kws={'s': 7}, label='Linear Model', scatter=False)\n",
    "\n",
    "ax1.set_xlim(df.index[0], df.index[-1])\n",
    "\n",
    "\n",
    "sns.move_legend(ax, \"upper left\", bbox_to_anchor=(1, 1))\n",
    "#x is ctd y is niskin?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_stage(weekNb):\n",
    "    if weekNb <8:\n",
    "        return 'Pre-bloom'\n",
    "    elif weekNb >= 8:\n",
    "        return 'Bloom'\n",
    "\n",
    "d1['Time'] = d1['weekn'].apply(get_stage)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df1 = d1[d1['Time'] == 'Bloom']\n",
    "df2 = d1[d1['Time'] == 'Pre-bloom']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "sns.lmplot(\n",
    "    data = d1,\n",
    "    x=\"weekn\", y=\"value\",\n",
    "    hue = 'variable', palette = 'viridis', scatter=True\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "sns.lmplot(x='weekn', y='value', data=df1, hue='variable') \n",
    "sns.lmplot(x='weekn', y='value', data=df2, hue='variable')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "d1 = all_md.loc[all_md['depth'] == 1]\n",
    "d1 = d1[['weekn', 'Temperature_x']]\n",
    "d1.rename(columns={'Temperature_x': 'Temperature'},\n",
    "          inplace= True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "d1.drop_duplicates(inplace=True)\n",
    "d1.set_index('weekn', inplace=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "rolling_mean = d1.rolling(5).mean()\n",
    "rolling_std = d1.rolling(5).std()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.plot(d1, color=\"blue\",label=\"Temperature\")\n",
    "plt.plot(rolling_mean, color=\"red\", label=\"Rolling Mean Temperature\")\n",
    "plt.plot(rolling_std, color=\"black\", label = \"Rolling Standard Deviation Temperate\")\n",
    "plt.title(\"Passenger Time Series, Rolling Mean, Standard Deviation\")\n",
    "#plt.legend(loc=\"upper right\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "autocorrelation_lag1 = d1['Temperature'].autocorr(lag=1)\n",
    "print(\"One Month Lag: \", autocorrelation_lag1)\n",
    "\n",
    "autocorrelation_lag3 = d1['Temperature'].autocorr(lag=3)\n",
    "print(\"Three Month Lag: \", autocorrelation_lag3)\n",
    "\n",
    "autocorrelation_lag6 = d1['Temperature'].autocorr(lag=6)\n",
    "print(\"Six Month Lag: \", autocorrelation_lag6)\n",
    "\n",
    "autocorrelation_lag9 = d1['Temperature'].autocorr(lag=9)\n",
    "print(\"Nine Month Lag: \", autocorrelation_lag9)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from statsmodels.tsa.seasonal import seasonal_decompose"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "decompose = seasonal_decompose(d1['Temperature'],model='multiplicative', period=3)\n",
    "trend = decompose.trend\n",
    "residual = decompose.resid\n",
    "\n",
    "decompose.plot();\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "sns.relplot(\n",
    "    data=d1, x=\"weekn\", y=\"value\",\n",
    "    row=\"depth\", hue=\"variable\",\n",
    "    kind=\"line\"\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Add prokaryotic community"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Data prep"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Found all 16S tables.\n",
      "Successfully saved all tables.\n"
     ]
    }
   ],
   "source": [
    "#generate a dataframe from all specified amplicon\n",
    "df, comm = consolidate_tables('16S')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Set up metadata ...\n",
      "Saved merged_asvs_metadata.tsv\n"
     ]
    }
   ],
   "source": [
    "merged = merge_metadata(df, all_md)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Appended all taxonomies to taxos\n",
      "Saved separated by metadata dataframe.\n"
     ]
    }
   ],
   "source": [
    "separated = pick_metadata(merged)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Remove chloroplast, cyanobacteria"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "searchfor = [\"Cyanobacteria\", \"Chloroplast\"]\n",
    "contaminants = separated[separated.Taxon.str.contains('|'.join(searchfor))]\n",
    "separated = separated[~separated.Taxon.str.contains('|'.join(searchfor))]\n",
    "separated = separated.reset_index(drop=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "separated = contaminants.copy()\n",
    "separated = separated.reset_index(drop=True)\n",
    "comm = 'chloroplast'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#add phytorep taxonomy\n",
    "cp_tax = pd.read_csv('chloroplast/taxonomy.tsv', sep='\\t')\n",
    "cp_tax = cp_tax.rename(columns={\"Feature ID\": \"feature_id\", \"Taxon\": \"PRTaxon\", \"Confidence\":\"PRConfidence\"})\n",
    "separated = pd.merge(separated, cp_tax, on=\"feature_id\", how=\"left\")\n",
    "separated['PRSpecies'] = separated['PRTaxon'].str.split('|').str[-1]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "separated['Total'] = separated['feature_frequency'].groupby(separated['sampleid']).transform('sum')\n",
    "separated['ratio'] = separated['feature_frequency']/separated['Total']\n",
    "separated['nASVs'] = separated['feature_id'].groupby(separated['sampleid']).transform('count')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "separated['weekdepth'] = separated[\"weekn\"].astype(str) + separated[\"depth\"].astype(str)\n",
    "separated['avg'] = separated['nASVs'].groupby(separated['weekdepth']).transform('mean')\n",
    "separated['diff'] = separated['nASVs'] - separated['avg']"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Run the following code to generate \"newseparated\" which is the union of small and large size fractions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "newseparated = make_defract(all_md, separated)\n",
    "newseparated[\"rank\"] = newseparated.groupby(\"sampleid\")[\"ratio\"].rank(method=\"average\", ascending=False)\n",
    "newseparated[\"ranktot\"] = newseparated['rank'] / newseparated['nASVs']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "separated = separated[separated.size_code != 'S']\n",
    "#separated = separated[separated.size_code != 'S']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#to import for weighted unifrac\n",
    "to_biom = onlyDFRW[['sampleid', 'feature_id', 'feature_frequency']].copy().drop_duplicates()\n",
    "to_biom = to_biom.pivot(index='sampleid', columns='feature_id', values='feature_frequency').fillna(0)\n",
    "to_biom.to_csv('newbiom'+comm+'.tsv', sep='\\t')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "table=onlyDFRW"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#loglog plot\n",
    "depths = [1,5,10,30,60]\n",
    "table = newseparated\n",
    "\n",
    "for depth in depths:\n",
    "    pca, pca_features, sfdclr, distance_matrix = pcaplot(table, depth, comm, 'size_code', 'DFr', 'week')\n",
    "    distance_matrix2 = distance_matrix.reset_index()\n",
    "    idedup = distance_matrix2['samples'].to_list()\n",
    "    dm = DistanceMatrix(distance_matrix, ids=idedup)\n",
    "    df123 = dm.to_data_frame()\n",
    "    df123.to_csv('outputs/'+comm+'/distance_matrix_d'+str(depth)+'.tsv', sep='\\t')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "upsetprep(comm, 'feature_id', separated)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "pca, pca_features, sfdclr, distance_matrix = pcaplot(newseparated, 1, comm, 'size_code', 'DFr', 'week')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "pca_features"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "import numpy as np\n",
    "\n",
    "from matplotlib.patches import Ellipse\n",
    "import matplotlib.transforms as transforms\n",
    "\n",
    "def get_correlated_dataset(n, dependency, mu, scale):\n",
    "    latent = np.random.randn(n, 2)\n",
    "    dependent = latent.dot(dependency)\n",
    "    scaled = dependent * scale\n",
    "    scaled_with_offset = scaled + mu\n",
    "    # return x and y of the new, correlated dataset\n",
    "    return scaled_with_offset[:, 0], scaled_with_offset[:, 1]\n",
    "\n",
    "fig, ax_nstd = plt.subplots(figsize=(6, 6))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "dependency_nstd = [[0.8, 0.75],\n",
    "                   [-0.2, 0.35]]\n",
    "mu = 0, 0\n",
    "scale = 8, 5"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "ax_nstd.axvline(c='grey', lw=1)\n",
    "ax_nstd.axhline(c='grey', lw=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "x, y = get_correlated_dataset(500, dependency_nstd, mu, scale)\n",
    "ax_nstd.scatter(x, y, s=0.5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "confidence_ellipse(x, y, ax_nstd, n_std=1,\n",
    "                   label=r'$1\\sigma$', edgecolor='firebrick')\n",
    "confidence_ellipse(x, y, ax_nstd, n_std=2,\n",
    "                   label=r'$2\\sigma$', edgecolor='fuchsia', linestyle='--')\n",
    "confidence_ellipse(x, y, ax_nstd, n_std=3,\n",
    "                   label=r'$3\\sigma$', edgecolor='blue', linestyle=':')\n",
    "\n",
    "ax_nstd.scatter(mu[0], mu[1], c='red', s=3)\n",
    "ax_nstd.set_title('Different standard deviations')\n",
    "ax_nstd.legend()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "confidence_ellipse(x, y, ax_nstd, n_std=1,\n",
    "                   label=r'$1\\sigma$', edgecolor='firebrick')\n",
    "confidence_ellipse(x, y, ax_nstd, n_std=2,\n",
    "                   label=r'$2\\sigma$', edgecolor='fuchsia', linestyle='--')\n",
    "confidence_ellipse(x, y, ax_nstd, n_std=3,\n",
    "                   label=r'$3\\sigma$', edgecolor='blue', linestyle=':')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "ax_nstd.scatter(mu[0], mu[1], c='red', s=3)\n",
    "ax_nstd.set_title('Different standard deviations')\n",
    "ax_nstd.legend()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "comm"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "pca, pca_features, sfdclr, distance_matrix = pcaplot(newseparated, 'all', comm, 'size_code', 'DFr', 'week')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#df=newseparated[newseparated.depth==1]\n",
    "df=newseparated.copy()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "topiv = df[['feature_id', 'feature_frequency', 'sampleid']].copy()\n",
    "topiv = topiv.drop_duplicates()\n",
    "\n",
    "sfdpiv= topiv.pivot(index='sampleid', columns='feature_id', values='feature_frequency')\n",
    "sfdpiv=sfdpiv.fillna(0)\n",
    "sfdclr=sfdpiv.mask(sfdpiv==0).fillna(0.1)\n",
    "clr_transformed_array = clr(sfdclr)\n",
    "samples = sfdpiv.index\n",
    "asvs = sfdpiv.columns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plot_df = pd.DataFrame(data = pca_features, columns = ['dim1', 'dim2'], index = sfdpiv.index)\n",
    "plot_df['dim1'] = plot_df['dim1']/1000\n",
    "plot_df['dim2'] = plot_df['dim2']/1000\n",
    "plot_df2 = pd.merge(plot_df,df[['sampleid','size_code','depth', 'weekn']],on='sampleid', how='left')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_stage(weekNb):\n",
    "    if weekNb < 8:\n",
    "        return 'Pre-bloom'\n",
    "    elif weekNb >= 8:\n",
    "        return 'Bloom'\n",
    "\n",
    "if depth != 'all':\n",
    "    plot_df2['Time'] = plot_df2['weekn'].apply(get_stage)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plot_df2.to_csv('R_results/R_testing_vis/for_R.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import plotly.express as px\n",
    "\n",
    "fig = px.scatter(plot_df2, x=\"dim1\", y=\"dim2\", color='size_code', symbol=\"depth\",\n",
    "                hover_data=['weekn', 'depth'])\n",
    "fig.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Write out fasta file of chloroplast/cyano sequences"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "fa = SeqIO.parse('chloroplast/dna-sequences.fasta' ,\n",
    "                 \"fasta\")\n",
    "seqs_i_want = [] #we'll put the good sequences here\n",
    "fid_chloro = newseparated['feature_id'].unique()\n",
    "for record in fa: #a SeqRecord has the accession as record.id, usually.\n",
    "    if record.id in fid_chloro: #This is how you check if the accession is in the values of the dict\n",
    "        seqs_i_want.append(record)\n",
    "#Now we can write the list of records to a fasta file. This will take care of the formatting etc\n",
    "with open('chloroplast/selected_dna.fasta', \"w\") as f:\n",
    "    SeqIO.write(seqs_i_want, f, \"fasta\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Richness analysis"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "sfd1 = newseparated[['sampleid','size_code', 'weekn', 'nASVs', 'depth']].copy()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#group the dataframe with all features to obtain either the mean or std of number of features per size fraction\n",
    "sfd1.groupby(['size_code']).mean()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "comm"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "sfd1.describe()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#run the visualisations for alpha diversity and run pairwise t-tests between size fractions for richness values\n",
    "anova, results = boxplot_depth(separated, comm, 5, 'nASVs', 'Number of ASVs')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "results"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "roll_avg(comm, newseparated, 1, 'nASVs',4)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df= newseparated[['sampleid', 'weekn','depth', 'size_code', 'nASVs']].copy()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df.drop_duplicates(inplace=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Simple regression analysis between pairs of size fractions"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "How to detect outliers?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "newseparated.loc[(newseparated['ratio'] > 0.25)].sort_values('ratio')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "q75, q25 = np.percentile(slwplot['L'], [75 ,25])\n",
    "iqr = q75 - q25"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "newslw = outlier(slwplot)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "newslw['L'].isna().sum()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "comm"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Run RL"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_results = SRA_pairs(comm, 'W', 'SL', newseparated, outliers='None', view=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_results"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "investigate temporal pattern thorugh all depths of outliers"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "supsel = newseparated.loc[newseparated['feature_id'] == '75ceeaa937c64399438614ca3706cf2a'].sort_values('feature_frequency')\n",
    "supsel['depth'].unique()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "sns.scatterplot(data = supsel, x = 'weekn', y = 'ratio', hue='depth')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#draw interactive plotly to identify outliers\n",
    "depth=1\n",
    "X='W'\n",
    "Y='L'\n",
    "\n",
    "d1 = newseparated.loc[newseparated['depth'] == depth]\n",
    "forpl = d1[['ratio', 'feature_id', 'sampleid', 'weekn', 'depth', 'size_code', 'Phylum', 'Family']].copy()\n",
    "slwplot = forpl.pivot_table(index=[\"feature_id\", \"depth\", 'weekn','Phylum', 'Family'], columns=\"size_code\", values='ratio').fillna(0)\n",
    "slwplot = slwplot.reset_index()\n",
    "fig = px.scatter(slwplot, x=X, y=Y, color=\"weekn\", trendline=\"ols\")\n",
    "fig.show()\n",
    "\n",
    "results = px.get_trendline_results(fig)\n",
    "print(results)\n",
    "\n",
    "#results.query(\"weekn ==  and Phylum == \").px_fit_results.iloc[0].summary()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Plot all r^2 values"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "r2vals = pd.read_csv(\"R_results/RL_results_ALL.csv\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "sns.set_theme(rc={'figure.figsize':(5,4)})\n",
    "sns.set_style(\"ticks\")\n",
    "sns.boxplot(data=r2vals, x=\"Y\", y=\"Rsq\", hue=\"Marker Gene\")\n",
    "plt.ylabel('R-squared', fontsize=12)\n",
    "plt.xlabel('Size fraction against total', fontsize=12)\n",
    "\n",
    "plt.savefig('outputs/'+'_rsq_both.png', dpi=200, bbox_inches=\"tight\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Calculate log2 fold change per feature at the phylum level of abundance between size fractions to identify which taxonomic group is driving the simple regression off x=y"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#add pseudo count for log-calculations and zero divisions\n",
    "slwplot['SL'] = slwplot['SL'] + 0.0000001\n",
    "slwplot['W'] = slwplot['W'] + 0.0000001\n",
    "\n",
    "#calculate log2 fold change\n",
    "slwplot['OR'] = (slwplot['W'] - slwplot['SL']) / slwplot['SL']\n",
    "slwplot['fold_change'] = slwplot['W']/slwplot['SL']\n",
    "slwplot['log2_fold_change'] = np.log2(slwplot['fold_change'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#make dual plot of log2FC and mean relative abundances side by side including error bars in the plots\n",
    "data = slwplot[['log2_fold_change','Phylum', 'W', 'SL']].copy()\n",
    "\n",
    "data['Phylum'] = data['Phylum'].map(lambda x: x.lstrip('p__'))\n",
    "\n",
    "# Group by index labels and take the means and standard deviations for each group\n",
    "data['avg_W'] = data['W'].groupby(data['Phylum']).transform('mean')\n",
    "data['std_W'] = data['W'].groupby(data['Phylum']).transform('std')\n",
    "data['avg_SL'] = data['SL'].groupby(data['Phylum']).transform('mean')\n",
    "data['std_SL'] = data['SL'].groupby(data['Phylum']).transform('std')\n",
    "data['means'] = data['log2_fold_change'].groupby(data['Phylum']).transform('mean')\n",
    "data['stds'] = data['log2_fold_change'].groupby(data['Phylum']).transform('std')\n",
    "\n",
    "data['positive'] = data['means'] > 0\n",
    "\n",
    "fig, axes = plt.subplots(ncols=2, sharey=True, figsize=(8, 10))\n",
    "\n",
    "axes[0].barh(data['Phylum'], data['means'],\n",
    "         xerr = data['stds'],\n",
    "         error_kw=dict(lw=0.5, capsize=1, capthick=0.5),\n",
    "         color=data.positive.map({True: 'g', False: 'r'}))\n",
    "\n",
    "axes[1].barh(data['Phylum'], data['avg_W'],\n",
    "            xerr = data['std_W'],\n",
    "         error_kw=dict(lw=0.5, capsize=1, capthick=0.5))\n",
    "\n",
    "#axes[2].barh(data['Phylum'], data['avg_SL'],\n",
    "#            xerr = data['std_SL'],\n",
    "#         error_kw=dict(lw=0.5, capsize=1, capthick=0.5))\n",
    "\n",
    "plt.gca().invert_yaxis()\n",
    "\n",
    "\n",
    "plt.savefig('outputs/'+comm_id+'/log2foldchange_d'+str(depth)+'.png', bbox_inches='tight', dpi=300)\n",
    "\n",
    "#plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#bar plot of log2FC per phylum without error bars\n",
    "data = slwplot[['log2_fold_change','Phylum']].copy()\n",
    "data['Phylum'] = data['Phylum'].map(lambda x: x.lstrip('p__'))\n",
    "\n",
    "# Group by index labels and take the means and standard deviations for each group\n",
    "#data['means'] = data['log2_fold_change'].groupby(data['Phylum']).transform('mean')\n",
    "#data['stds'] = data['log2_fold_change'].groupby(data['Phylum']).transform('std')\n",
    "\n",
    "data['positive'] = data['log2_fold_change'] > 0\n",
    "\n",
    "plt.figure(figsize=(6,11))\n",
    "plt.barh(data['Phylum'], data['log2_fold_change'],\n",
    "         color=data.positive.map({True: 'g', False: 'r'}))\n",
    "plt.gca().invert_yaxis()\n",
    "\n",
    "plt.savefig('outputs/'+comm_id+'/log2foldchange_d'+str(depth)+'_noerr.png', bbox_inches='tight', dpi=300)\n",
    "\n",
    "#plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "not_in_W = slwplot.loc[slwplot['W'] == 0]\n",
    "#not_in_W['feature_id'].nunique()\n",
    "not_in_W_from_S = not_in_W.loc[not_in_W['L'] == 0]\n",
    "#not_in_W_from_S['feature_id'].nunique()\n",
    "\n",
    "#calculate the percentage of features coming from the small size fraction that are absent from the whole  \n",
    "not_in_W_from_S['feature_id'].nunique()/not_in_W['feature_id'].nunique()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "sns.scatterplot(data=not_in_W, x='S', y='SL', hue='weekn')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### run lmplot for each pair of sets"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#loglog plot\n",
    "depths = [1,5,10,30,60]\n",
    "\n",
    "for depth in depths:\n",
    "    d1 = newseparated.loc[newseparated['depth'] == depth]\n",
    "    forpl = d1[['ratio', 'feature_id', 'sampleid', 'weekn', 'depth', 'size_code', 'Phylum']].copy()\n",
    "    slwplot = forpl.pivot_table(index=[\"feature_id\", \"depth\", 'weekn', 'Phylum'], columns=\"size_code\", values='ratio').fillna(0)\n",
    "    slwplot = slwplot.reset_index()\n",
    "    sns.set_style(\"white\")\n",
    "\n",
    "    #slwplot = slwplot.loc[slwplot['weekn'] = 10]\n",
    "    #slwplot = slwplot.loc[slwplot['weekn'] = 11]\n",
    "\n",
    "    slwplot = slwplot.rename(columns={\"depth\": \"Depth\"})\n",
    "    slwplot[\"weekn\"] = pd.to_numeric(slwplot[\"weekn\"])\n",
    "    g = sns.scatterplot(x=\"W\", y=\"SL\", data=slwplot, palette=['black'])#, hue='Phylum', alpha=0.6) #, hue=\"weekn\");\n",
    "    \n",
    "    #uncomment for log-log\n",
    "    #ax.set(xscale=\"log\", yscale=\"log\")\n",
    "    g.set_ylabel(\"Defractionated\",fontsize=15)\n",
    "    g.set_xlabel(\"Unfractionated\",fontsize=15)\n",
    "    g.tick_params(labelsize=12)\n",
    "    #g.legend(loc='center left', bbox_to_anchor=(1.25, 0.5), ncol=3)\n",
    "    plt.legend([],[], frameon=False)\n",
    "    \n",
    "    #plt.savefig('outputs/lmplot_'+comm+str(depth)+'WSL.png', bbox_inches='tight', dpi=300)\n",
    "\n",
    "    plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Phylogenetic analysis: taxonomic bar plots of relative abundance per depth and size fraction"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "if comm == 'chloroplast':\n",
    "    level = 'PRTaxon'\n",
    "else:\n",
    "    level = 'Species'\n",
    "#get a list of top taxa to provide the palette for the visualisation\n",
    "toptaxa = separated[['feature_id', 'feature_frequency', 'Taxon', 'size_code', 'depth','weekn', level]].copy()\n",
    "toptaxa = toptaxa.drop_duplicates()\n",
    "df_agg = toptaxa.groupby(['size_code',level, 'depth']).agg({'feature_frequency':sum})\n",
    "topd = df_agg['feature_frequency'].groupby(['size_code', 'depth'], group_keys=False).nlargest(10)\n",
    "topd = topd.to_frame()\n",
    "topd = topd.reset_index()\n",
    "listoftop = topd[level].unique()\n",
    "\n",
    "#set a palette for the toptaxa\n",
    "hex_colors_dic = {}\n",
    "rgb_colors_dic = {}\n",
    "hex_colors_only = []\n",
    "for name, hex in matplotlib.colors.cnames.items():\n",
    "    hex_colors_only.append(hex)\n",
    "    hex_colors_dic[name] = hex\n",
    "    rgb_colors_dic[name] = matplotlib.colors.to_rgb(hex)\n",
    "    \n",
    "palette_dict = {taxon: color for taxon, color in zip(listoftop, px.colors.sequential.Plasma)}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "taxbarplot(separated, level, 5, 10, palette_dict, 'size_code')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Top taxon longitudinal analysis"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# newseparated.loc[(newseparated['weekn']==12)&\n",
    "#                  (newseparated['depth']==10)]\n",
    "#                & (newseparated['size_code']=='W')]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "sfd=newseparated\n",
    "if comm == 'chloroplast':\n",
    "    level = 'PRSpecies'\n",
    "else:\n",
    "    level = 'Genus'\n",
    "toptaxa = sfd[['feature_id', 'feature_frequency', 'Taxon', 'size_code', 'depth','weekn', level]].copy()\n",
    "toptaxa = toptaxa.drop_duplicates()\n",
    "df_agg = toptaxa.groupby(['size_code',level, 'depth', 'weekn']).agg({'feature_frequency':sum})\n",
    "topd = df_agg['feature_frequency'].groupby(['size_code', 'depth','weekn'], group_keys=False).nlargest(1)\n",
    "topd = topd.to_frame()\n",
    "topd = topd.reset_index()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#if looking at groups of top\n",
    "newdf = topd.groupby(['size_code', 'depth','weekn'])[level].apply(lambda x: list(set(x)))\n",
    "newdf = newdf.reset_index()\n",
    "\n",
    "result = newdf.copy()\n",
    "\n",
    "result = newdf.Genus.sort_values().apply(lambda x: sorted(x))\n",
    "result = pd.DataFrame(result).reset_index(drop=True)\n",
    "\n",
    "result['liststring'] = result[level].apply(lambda x: ','.join(map(str, x)))\n",
    "result['liststring'].unique()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "type_dic = {'g__Alteromonas':1, 'g__Candidatus_Nitrosopumilus':2, 'g__Clade_Ia':3,\n",
    "       'g__Colwellia':4, 'g__Fluviicola':5, 'g__NS3a_marine_group':6,\n",
    "       'g__OM190':7, 'g__Planktomarina':8, 'g__Polaribacter':9,\n",
    "       'g__Polycyclovorans':10, 'g__Pseudomonas':11, 'g__SUP05_cluster':12,\n",
    "       'g__Sulfitobacter':13, 'g__Ulvibacter':14, 'g__uncultured':15}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "result['comm_type'] = ''\n",
    "\n",
    "for tx, ctype in type_dic.items():\n",
    "    result.loc[result['liststring'] == tx, 'comm_type'] = ctype\n",
    "    \n",
    "result\n",
    "topd = result.copy()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#list the unique top taxa\n",
    "topd[level].unique()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "type_dic = {'Teleaulax':1, 'Thalassiosira':2, 'Chaetoceros':3, 'Unassigned':4,\n",
    "       'Eutreptiella':5, 'Micromonas':6, 'Phaeocystis':7,\n",
    "       'uncultured+bacterium':8, 'Haptolina':9, 'Chrysochromulina':10}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "type_dic = {\n",
    "    #\"c__Cyanobacteriia\": 1,\n",
    "    \"c__OM190\": 3,\n",
    "    \"c__Bacteroidia\": 2,\n",
    "    \"c__Gammaproteobacteria\": 5,\n",
    "    \"c__Alphaproteobacteria\": 4}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "topd['comm_type'] = ''\n",
    "\n",
    "for tx, ctype in type_dic.items():\n",
    "    topd.loc[topd[level] == tx, 'comm_type'] = ctype\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "topd[\"sc_weekn\"] = topd[\"depth\"].astype(str) + topd[\"size_code\"]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "topd = topd.sort_values(['depth', 'size_code'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "topdlist = topd['sc_weekn'].tolist()\n",
    "\n",
    "def uniqlist(seq):\n",
    "    seen = set()\n",
    "    seen_add = seen.add\n",
    "    return [x for x in seq if not (x in seen or seen_add(x))]\n",
    "\n",
    "mylist = uniqlist(topdlist)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "glue = topd.pivot(index=\"sc_weekn\", columns=\"weekn\", values=\"comm_type\")\n",
    "glue = glue.reindex(mylist)\n",
    "glue = glue[glue.columns].astype(float)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from matplotlib.colors import ListedColormap\n",
    "cmap_dict = {1: '#77AADD',\n",
    "             2: '#EEDD88', 3: '#99DDFF', 4: '#BBCC33', 5:'#DDDDDD', 6:'#D35FB7', 7:}\n",
    "cmap = ListedColormap([cmap_dict[i] for i in range(1,7,1)])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from matplotlib.colors import ListedColormap\n",
    "cmap_dict = {1: '#9e0142',\n",
    "             2: '#d53e4f', 3: '#f46d43', 4: '#fdae61',\n",
    "             5:'#fee08b', 6:'#e6f598', 7:'#abdda4',\n",
    "            8:'#66c2a5', 9:'#3288bd', 10:'#5e4fa2'}\n",
    "cmap = ListedColormap([cmap_dict[i] for i in range(1,11,1)])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "cmap = plt.get_cmap('tab20', 15)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "sns.set_style('ticks')\n",
    "plt.figure(figsize=(5, 5))\n",
    "\n",
    "\n",
    "ax = sns.heatmap(glue, fmt='f', yticklabels=True, linewidths=.5, cmap=cmap)\n",
    "ax.axhline(4, ls='--')\n",
    "ax.axhline(8, ls='--')\n",
    "ax.axhline(12, ls='--')\n",
    "ax.axhline(16, ls='--')\n",
    "\n",
    "ax.set_xticks(range(1, 16, 4))\n",
    "\n",
    "plt.savefig('outputs/'+comm+'/heatmap_top1_16s_genus.png', bbox_inches='tight', dpi=300)\n",
    "\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Longitudinal analysis of top 3 taxa"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Run these lines only for the 18S rRNA analysis"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#18S has many more classes as top values to\n",
    "top518s = topd['Class'].value_counts()[:4].index.tolist()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "topd.loc[~topd[\"Class\"].isin(top518s), \"Class\"] = \"Other\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#if looking at groups of top\n",
    "\n",
    "newdf = topd.groupby(['size_code', 'depth','weekn'])['Class'].apply(lambda x: list(set(x)))\n",
    "newdf = newdf.reset_index()\n",
    "\n",
    "result = newdf.copy()\n",
    "\n",
    "result = newdf.Class.sort_values().apply(lambda x: sorted(x))\n",
    "result = pd.DataFrame(result).reset_index(drop=True)\n",
    "\n",
    "result['liststring'] = result['Class'].apply(lambda x: ','.join(map(str, x)))\n",
    "result['liststring'].unique()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "result.Class.apply(tuple).unique()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "topd['Class'].unique()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "type_dic = {\n",
    "    'c__Cryptophyceae':1, 'c__Dinophyceae':2, 'c__Prymnesiophyceae':3,\n",
    "       'c__Mediophyceae':4, 'c__Monogononta':5, 'c__Tentaculata':6,\n",
    "       'c__Maxillopoda':7, 'c__Thecofilosea':8, 'Unassigned':9, 'c__Insecta':10,\n",
    "       'c__MAST-2':11, 'c__Hydrozoa':12, 'c__Syndiniales':13,\n",
    "       'c__Intramacronucleata':14, 'c__Pucciniomycetes':15,\n",
    "       'c__Mamiellophyceae':16, 'c__Raphidophyceae':17, 'c__MAST-1A':18,\n",
    "       'c__Bicosoecida':19, 'c__Polychaeta':20, 'c__Tremellomycetes':21,\n",
    "       'c__Embryophyta':22, 'c__Dothideomycetes':23, 'c__Incertae_Sedis':24,\n",
    "       'c__MAST-7A':25\n",
    "}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "type_dic = {'Other':5, 'c__Dinophyceae':1, 'c__Mediophyceae':2,\n",
    "       'c__Intramacronucleata':3, 'c__Syndiniales':4}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#use this dic if looking at community type by 3 top taxa\n",
    "type_dic = {'c__Bacteroidia,c__Cyanobacteriia,c__OM190':1,\n",
    "       'c__Gammaproteobacteria,c__Bacteroidia,c__Cyanobacteriia':2,\n",
    "       'c__Alphaproteobacteria,c__Bacteroidia,c__Cyanobacteriia':3,\n",
    "       'c__Bacteroidia,c__Cyanobacteriia,c__Planctomycetes':4,\n",
    "       'c__Bacteroidia,c__Alphaproteobacteria,c__OM190':5,\n",
    "       'c__Bacteroidia,c__OM190,c__Planctomycetes':6,\n",
    "       'c__Gammaproteobacteria,c__Bacteroidia,c__OM190':7,\n",
    "       'c__Gammaproteobacteria,c__Bacteroidia,c__Planctomycetes':8,\n",
    "       'c__Cyanobacteriia,c__OM190,c__Planctomycetes':9,\n",
    "       'c__Alphaproteobacteria,c__Gammaproteobacteria,c__Cyanobacteriia':10,\n",
    "       'c__Gammaproteobacteria,c__Bacteroidia,c__Alphaproteobacteria':11,\n",
    "       'c__Bacteroidia,c__Alphaproteobacteria,c__Cyanobacteriia':12,\n",
    "       'c__Nitrososphaeria,c__Gammaproteobacteria,c__Bacteroidia':13,\n",
    "       'c__Gammaproteobacteria,c__Alphaproteobacteria':14,\n",
    "       'c__Cyanobacteriia':15}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#make a season column\n",
    "topd['comm_type'] = ''\n",
    "\n",
    "for tx, ctype in type_dic.items():\n",
    "    topd.loc[topd['Genus'] == tx, 'comm_type'] = ctype\n",
    "    \n",
    "topd"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "result['comm_type'] = ''\n",
    "\n",
    "for tx, ctype in type_dic.items():\n",
    "    result.loc[result['liststring'] == tx, 'comm_type'] = ctype\n",
    "    \n",
    "result\n",
    "topd = result.copy()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "topd[\"sc_weekn\"] = topd[\"depth\"].astype(str) + topd[\"size_code\"]\n",
    "topd"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "topd = topd.sort_values(['depth', 'size_code'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "topdlist = topd['sc_weekn'].tolist()\n",
    "\n",
    "def uniqlist(seq):\n",
    "    seen = set()\n",
    "    seen_add = seen.add\n",
    "    return [x for x in seq if not (x in seen or seen_add(x))]\n",
    "\n",
    "mylist = uniqlist(topdlist)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "glue = topd.pivot(index=\"sc_weekn\", columns=\"weekn\", values=\"comm_type\")\n",
    "glue = glue.reindex(mylist)\n",
    "glue = glue[glue.columns].astype(float)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    " '#77AADD', '#EE8866', '#EEDD88', '#FFAABB', '#99DDFF', '#44BB99', '#BBCC33', '#AAAA00', '#DDDDDD'."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from matplotlib.colors import ListedColormap\n",
    "cmap_dict = {1: '#77AADD', 2: '#EEDD88', 3: '#99DDFF', 4: '#BBCC33', 5:'#DDDDDD'}\n",
    "cmap = ListedColormap([cmap_dict[i] for i in range(1,6,1)])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "cmap_dict ={1:'#125A56', 2:'#00767B', 3:'#238F9D', 4:'#42A7C6', 5:'#60BCE9',\n",
    "            6:'#9DCCEF', 7:'#C6DBED', 8:'#DEE6E7', 9:'#ECEADA', 10:'#F0E6B2',\n",
    "            11:'#F9D576', 12:'#FFB954', 13:'#FD9A44', 14:'#F57634', 15:'#E94C1F'}#, '#D11807', '#A01813'.\n",
    "cmap = ListedColormap([cmap_dict[i] for i in range(1,16,1)])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "sns.set_style('ticks')\n",
    "plt.figure(figsize=(5, 5))\n",
    "\n",
    "\n",
    "ax = sns.heatmap(glue, fmt='f', yticklabels=True, linewidths=.5, cmap=cmap)\n",
    "ax.axhline(4, ls='--')\n",
    "ax.axhline(8, ls='--')\n",
    "ax.axhline(12, ls='--')\n",
    "ax.axhline(16, ls='--')\n",
    "\n",
    "ax.set_xticks(range(1, 16, 4))\n",
    "\n",
    "\n",
    "plt.savefig('outputs/heatmap_'+comm+'top1class_reducde.png', bbox_inches='tight', dpi=300)\n",
    "\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Taxonomy plotting"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "    sfd=separated[separated.depth==depth]\n",
    "    toptaxa = sfd[['feature_id', 'feature_frequency', 'Taxon', 'size_code', 'depth','weekn', level]].copy()\n",
    "    toptaxa = toptaxa.drop_duplicates()\n",
    "    df_agg = toptaxa.groupby(['size_code',level, 'depth']).agg({'feature_frequency':sum})\n",
    "    topd = df_agg['feature_frequency'].groupby('size_code', group_keys=False).nlargest(topn)\n",
    "    topd = topd.to_frame()\n",
    "    topd = topd.reset_index()\n",
    "\n",
    "\n",
    "    df_agg = df_agg.reset_index()\n",
    "    df_agg['set_name'] = df_agg['size_code']+df_agg['depth'].astype(str)\n",
    "    \n",
    "    cumulab = separated[['feature_frequency', 'depth', 'size_code', 'Genus']].copy()\n",
    "    cumulab1 = cumulab.groupby(['Genus']).agg({'feature_frequency':sum})\n",
    "\n",
    "    resultpivot = df_agg.pivot_table(index=level, columns='set_name', values='feature_frequency')\n",
    "    resultpivot = resultpivot.fillna(0)\n",
    "    resultpivot[resultpivot != 0] = 1\n",
    "    tosave = pd.merge(resultpivot, cumulab1, left_index=True, right_index=True)\n",
    "    tosave.to_csv(level+'_'+str(depth)+'16S_relab.csv')\n",
    "    \n",
    "    top10d_list = topd[level].unique()\n",
    "    top10d = sfd.copy()\n",
    "    top10d.loc[~top10d[level].isin(top10d_list), level] = 'Other' #isnot in top list\n",
    "    phyld = top10d.groupby(['size_code','weekn', level])['ratio'].sum()\n",
    "    phyld = phyld.reset_index()\n",
    "\n",
    "\n",
    "    fig = px.bar(phyld, x=\"size_code\", y=\"ratio\", facet_col=\"weekn\", color=level, labels={\n",
    "                     \"feature_frequency\": \"Relative abundance\",\n",
    "                     \"size_code\": \"\",\n",
    "                     \"weekn\": \"w\"}, color_discrete_map=palette_dict)\n",
    "    fig.update_xaxes(type='category', dtick=1)\n",
    "    fig.update_layout(\n",
    "        title=\"Relative abundance of top 10\" + level + 'observed at Depth' + str(depth),\n",
    "        yaxis_title=\"Relative abundance\",\n",
    "        xaxis_title=\"Size fraction\",\n",
    "        legend_title=level,\n",
    "        font=dict(size=8)\n",
    "    )\n",
    "\n",
    "    fig.show()\n",
    "    #fig.write_image(\"outputs/fig1.png\")\n",
    "    #fig.to_image(format=\"png\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "phyld, top10d = taxbarplot(newseparated, 'Class', 5, 5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plot_df2 = plot_df2.drop_duplicates()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plot_df3 = plot_df2.set_index('sampleid')\n",
    "plot_df3"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "permanova2 = permanova(dm, plot_df3, 'Size code')\n",
    "permanova2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "pca, pca_features, sfdclr, dm = pcaplot(table, 60, comm, 'size_code', 'DFr', 'week')\n",
    "distance_matrix2 = distance_matrix.reset_index()\n",
    "idedup = distance_matrix2['samples'].to_list()\n",
    "dm = DistanceMatrix(distance_matrix, ids=idedup)\n",
    "df123 = dm.to_data_frame()\n",
    "df123.to_csv('distance_matrix_5m16s.tsv', sep='\\t')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "distance_matrix2 = distance_matrix.reset_index()\n",
    "idedup = distance_matrix2['samples'].to_list()\n",
    "dm = DistanceMatrix(distance_matrix, ids=idedup)\n",
    "df123 = dm.to_data_frame()\n",
    "df123.to_csv('distance_matrix_5m16s.tsv', sep='\\t')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df123.to_csv('distance_matrix_5m16s.tsv', sep='\\t')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plot_df2.to_csv('METADATAtiny.txt', sep='\\t')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "pca, pca_features, sfdclr, dm = pcaplot(onlyDFRW, 'all', comm, 'Size code', 'DFr', 'week')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "newdm = dm.stack().reset_index().sort_values(0)\n",
    "newdm = newdm[newdm['samples'] != newdm['sampleid']]\n",
    "newdm[\"depth_codes\"] = newdm[\"samples\"].str.extract(r'[1-9][0-9]?([A-E])')\n",
    "newdm[\"depth_code\"] = newdm[\"sampleid\"].str.extract(r'[1-9][0-9]?([A-E])')\n",
    "newdm[\"weeknsamples\"] = newdm[\"samples\"].str.extract(r'\\.([1-9][0-9]?)[A-E]')\n",
    "newdm[\"weeknsampleid\"] = newdm[\"sampleid\"].str.extract(r'\\.([1-9][0-9]?)[A-E]')\n",
    "newdm = newdm[newdm['weeknsampleid'] == newdm['weeknsamples']]\n",
    "newdm = newdm[newdm['depth_codes'] == newdm['depth_code']]\n",
    "newdm.to_csv('outputs/'+comm+'/compareall.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "sns.set_style('ticks')\n",
    "newdm['weeknsamples'] = pd.to_numeric(newdm['weeknsamples'])\n",
    "\n",
    "g=sns.lineplot(data=newdm, x=\"weeknsamples\", y=0, hue=\"depth_codes\", hue_order = ['A', 'B', 'C', 'E', 'D'],\n",
    "              palette=sns.color_palette(\"Blues\"))\n",
    "sns.move_legend(g,\"upper left\", bbox_to_anchor=(1, 1), title='Depth')\n",
    "g.set(xlabel='Time(weeks)', ylabel='Euclidean distance', title=comm)\n",
    "\n",
    "plt.savefig('outputs/'+comm+'/eucldist.png', dpi=200, bbox_inches=\"tight\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "! conda install bioconda::bioconductor-aldex2 --yes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "newmetadata = newseparated[['sampleid', 'weekn', 'size_code', 'depth', 'depth_code', 'month_name']].copy()\n",
    "newmetadata = newmetadata.drop_duplicates()\n",
    "newmetadata.to_csv('METADATA.tsv', sep='\\t')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "pca_features"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from skbio.stats.distance import permanova"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Stacked bar plots"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "comm"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "level = 'feature_id'\n",
    "if level == 'feature_id':\n",
    "    id = 'ASV'\n",
    "else:\n",
    "    id = level\n",
    "\n",
    "subtitile = 'subtitle'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "dfplot, level = calcperc(comm, separated, level)\n",
    "# variables\n",
    "labels = ['S', 'L','S ∩ L', 'W', 'W ∩ (S ∩ L)']\n",
    "colors = ['#5975a4','#d55e00','#D39473', '#6EAF46', '#9F946E']\n",
    "title = 'Weighted proportion of shared '+id+' between size fractionated and non size fractionated samples'\n",
    "\n",
    "plot_stackedbar_p(comm, dfplot, labels, colors, title, subtitle, level)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "dfplot16s = dfplot.copy()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "dfplot18s = dfplot.copy()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "newchl = dfplotchloro/3"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "new18 = dfplot18s/3"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "new16 = dfplot16s/3"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "newdfplot = newchl+new18+new16"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "new18"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "new16"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "newchl"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "dfplot18s"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "dfplotSLNSF"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "data = {'Depth':['1','5','10','30','60'],\n",
    "    'Sonly': [3, 3, 3, 2.644278, 3],\n",
    "        'Lonly': [0, 0, 0, 0.4, 0],\n",
    "        'LS': [0, 0, 0, 0,0],\n",
    "       'NSF': [0, 0, 0, 0,0]}\n",
    "dfplotSLNSF = pd.DataFrame(data)\n",
    "dfplotSLNSF2 = dfplotSLNSF.set_index('Depth')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "dfplotSLNSF2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "dfplotSLNSF, dfplot_normalized, level = calcperc_SLNSF(comm, newseparated, level)\n",
    "# variables\n",
    "labels = ['S', 'L','S ∩ L', 'W']\n",
    "colors = ['#5975a4','#d55e00','#D39473', '#6EAF46']\n",
    "title = 'Weighted proportion of shared '+ id +' between size fractionated and non size fractionated samples'\n",
    "\n",
    "plot_stackedbar_p_SLNSF(comm, dfplotSLNSF, labels, colors, title, subtitle, level, 30.1, 5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "newbiom = d1.pivot_table(index=\"feature_id\", columns=\"sampleid\", values=\"feature_frequency\")\n",
    "newbiom = newbiom.fillna(0)\n",
    "newbiom.to_csv('newbiomdepth1.tsv', sep=\"\\t\") "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 16S ANCOM PER DEPTH"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "** another idea is to run ancom of sizefraction specific and compare after the categories (run ancom on ?time or month.. or some other column) and compare the number/taxonomy of differentially abundant taxa recovered;\n",
    "are we recovering the same diff ab taxa between the (1.SF samples, 2. NSF samples)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#uncomment if you want to exclude the Large size fraction from the ANCOM\n",
    "#onlyDFRW = newseparated[newseparated.size_code != 'L']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "depth = 5\n",
    "pca, pca_features, sfdclr, dm = pcaplot(separated, depth, comm, 'size_code', 'DFr', 'week')\n",
    "DAresults, DARejected_SC_taxonomy, prcentile = run_ancom(comm, separated, sfdclr, depth, 'size_code')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "DAresults"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "topiv = onlyDFRW[['feature_id', 'feature_frequency', 'sampleid']].copy()\n",
    "topiv = topiv.drop_duplicates()\n",
    "\n",
    "sfdpiv= topiv.pivot(index='sampleid', columns='feature_id', values='feature_frequency')\n",
    "sfdpiv=sfdpiv.fillna(0)\n",
    "sfdclr=sfdpiv.mask(sfdpiv==0).fillna(0.1)\n",
    "clr_transformed_array = clr(sfdclr)\n",
    "samples = sfdpiv.index\n",
    "asvs = sfdpiv.columns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Creating the dataframe with the clr transformed data, and assigning the sample names\n",
    "clr_transformed = pd.DataFrame(clr_transformed_array, columns=asvs)\n",
    "#Assigning the asv names\n",
    "clr_transformed['samples'] = samples\n",
    "clr_transformed = clr_transformed.set_index('samples')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "clr_transformed.reset_index(inplace=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "clr_transformed[\"size_code\"] = clr_transformed[\"samples\"].str.extract(r'[1-9][0-9]?[A-E]([SL])')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "clr_transformed[\"size_code\"] = clr_transformed[\"size_code\"].fillna('W')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "clr_transformed = clr_transformed.melt(id_vars=['samples', 'size_code'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "clr_transformed['clrmean'] = clr_transformed.groupby(['size_code', 'feature_id']).transform('mean')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "clr_transformed.drop(['value', 'samples'], axis=1, inplace=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "clr_transformed = clr_transformed.drop_duplicates()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "clr_transformed.drop(['size_code'], axis=1, inplace=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "clr_transformed['clrdiff'] = clr_transformed.groupby(['feature_id']).transform('diff')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "clr_transformed.drop(['clrmean'], axis=1, inplace=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "clr_transformed = clr_transformed.drop_duplicates()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "clr_transformed.dropna(subset=[\"clrdiff\"], inplace=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "merged_df = pd.merge(DAresults, clr_transformed, on='feature_id')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "merged_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import plotly.express as px\n",
    "fig = px.scatter(merged_df, x=\"clrdiff\", y=\"W\", hover_name=\"Taxon\")#, hover_data=[\"continent\", \"pop\"])\n",
    "fig.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "comm"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "depths = [1,5,10,30,60]\n",
    "table = separated\n",
    "for depth in depths:\n",
    "    pca, pca_features, sfdclr, dm = pcaplot(table, depth, comm, 'size_code', 'DFr', 'week')\n",
    "    DAresults, DARejected_SC_taxonomy, prcentile = run_ancom(comm, table, sfdclr, depth, 'size_code')\n",
    "    DAresults.to_csv('outputs/'+comm+'/DARejected'+str(depth)+'.csv')\n",
    "    DARejected_SC_taxonomy.to_csv('outputs/'+comm+'/DARejected_SC_taxonomy'+str(depth)+'.csv')\n",
    "    prcentile.to_csv('outputs/'+comm+'/prcentile'+str(depth)+'.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "prcentile"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "dfL = prcentile.xs('L', axis=1, level=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "dfL['size_code']='L'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "dfS = prcentile.xs('S', axis=1, level=1)\n",
    "dfS['size_code']='S'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "new= pd.merge(dfL, dfS, on='feature_id')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "new"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "new"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import plotly.express as px\n",
    "df = px.data.iris()\n",
    "fig = px.scatter(df, x=\"sepal_width\", y=\"sepal_length\", color=\"species\", symbol=\"species\")\n",
    "fig.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "prcentile1_16 = prcentile1_16.reset_index()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "prcentile1_16.loc[prcentile1_16['feature_id'] == 'a955e3b357dd61bebe626bf1d0af33c4']"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Group-specific time series"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "fids = ['2981aa9f69bc423dc502b2e178dc7904',\n",
    "'6c987094eb76bff568a4499383aa85e6',\n",
    "'a8651618911e5bb5d1066e5abca8f322']\n",
    "depth = 1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "subplots(comm, 1, fids, 3, newseparated)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "save_individual_plots(comm,depth,fid,newseparated)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "save_all4_plots(comm,depth,fid,newseparated)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Permanova results from R into boxplots"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "permresu = pd.read_csv('R_results/post_hoc_results.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "permresu[\"depth_pairs\"] = permresu[\"depth\"].astype(str) + permresu[\"pairs\"]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "ax = sns.catplot(\n",
    "    permresu, kind=\"bar\",\n",
    "    x=\"p.adjusted\", y=\"pairs\", col=\"comm\", hue=\"depth\",\n",
    "    height=4, aspect=1.3, palette=\"Greys\", log=True\n",
    ")\n",
    "#ax.set(xlim=(0, 0.10))\n",
    "\n",
    "ax.refline(x=0.05, color='red')\n",
    "\n",
    "plt.savefig('outputs/perm_pvalues_logged.png', bbox_inches='tight', dpi=300)\n",
    "\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "ax = sns.catplot(\n",
    "    permresu, kind=\"bar\",\n",
    "    x=\"p.adjusted\", y=\"pairs\", col=\"comm\", hue=\"depth\",\n",
    "    height=4, aspect=1.3, palette=\"Greys\", log=True\n",
    ")\n",
    "#ax.set(xlim=(0, 0.10))\n",
    "\n",
    "ax.refline(x=0.05, color='red')\n",
    "\n",
    "plt.savefig('outputs/perm_pvalues_logged.png', bbox_inches='tight', dpi=300)\n",
    "\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "qiime2-2023.5",
   "language": "python",
   "name": "qiime2-2023.5"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.16"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
